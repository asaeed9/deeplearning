{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"/home/asaeed9/work/data/2cat/sample\"\n",
    "results_path = \"/home/asaeed9/work/data/2cat/sample/results\"\n",
    "test_path = path + '/test/' #We use all the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "import os, sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from math import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import image, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n"
     ]
    }
   ],
   "source": [
    "%cd /home/asaeed9/work/data/2cat/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g = glob('*.jpg')\n",
    "# shuf = np.random.permutation(g)\n",
    "# for i in range(5000): os.rename(shuf[i], '../valid/' + shuf[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g = glob('*.jpg')\n",
    "# shuf = np.random.permutation(g)\n",
    "# for i in range(1000): os.rename(shuf[i], '../test/' + shuf[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy training images\n",
    "def copy_samples(n):\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(n): copyfile(shuf[i], '../sample/train/' + shuf[i]) \n",
    "    %mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "    %mv ../sample/train/dog*.jpg ../sample/train/dogs/\n",
    "    \n",
    "    %cd ../valid\n",
    "\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(5000): copyfile(shuf[i], '../sample/valid/' + shuf[i]) \n",
    "    %mv ../sample/valid/cat*.jpg ../sample/valid/cats/\n",
    "    %mv ../sample/valid/dog*.jpg ../sample/valid/dogs/\n",
    "    %cd /home/asaeed9/work/data/2cat/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_up():\n",
    "    %rm $path/train/cats/*\n",
    "    %rm $path/train/dogs/*\n",
    "    %rm $path/valid/cats/*\n",
    "    %rm $path/valid/dogs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_expected_labels(filenames):\n",
    "    expected_labels = []\n",
    "    for elem in filenames:\n",
    "        if 'dog' in elem:\n",
    "            expected_labels.append(1)\n",
    "        elif 'cat' in elem:\n",
    "            expected_labels.append(0)\n",
    "    return np.array(expected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n"
     ]
    }
   ],
   "source": [
    "%cd /home/asaeed9/work/data/2cat/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘/train/cats/*’: No such file or directory\n",
      "rm: cannot remove ‘/train/dogs/*’: No such file or directory\n",
      "rm: cannot remove ‘/valid/cats/*’: No such file or directory\n",
      "rm: cannot remove ‘/valid/dogs/*’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "clean_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_nn(batches, val_batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.optimizer.lr = 0.0001\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import *\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n",
      "sample size: 15000\n",
      "/home/asaeed9/work/data/2cat/valid\n",
      "/home/asaeed9/work/data/2cat/train\n",
      "ls: cannot access /train/cats/: No such file or directory\n",
      "0\n",
      "ls: cannot access /train/dogs/: No such file or directory\n",
      "0\n",
      "ls: cannot access /valid/cats/: No such file or directory\n",
      "0\n",
      "ls: cannot access /valid/dogs/: No such file or directory\n",
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-17ef7693f200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtr_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mval_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "%cd /home/asaeed9/work/data/2cat/train\n",
    "#for n in range(1000, 5001, 1000):\n",
    "n = 15000\n",
    "print('sample size: {}'.format(n))\n",
    "copy_samples(n)\n",
    "\n",
    "%ls -ltra $path/train/cats/ | wc -l\n",
    "%ls -ltra $path/train/dogs/ | wc -l\n",
    "%ls -ltra $path/valid/cats/ | wc -l\n",
    "%ls -ltra $path/valid/dogs/ | wc -l\n",
    "\n",
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "            shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "\n",
    "tr_batches = gen_t.flow_from_directory(path + '/train', batch_size=batch_size)\n",
    "val_batches = gen_t.flow_from_directory(path + '/valid', class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "mod = conv_nn(tr_batches, val_batches)\n",
    "\n",
    "# gen_test = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "#         shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "test_batches = get_t.flow_from_directory(test_path, batch_size=batch_size)\n",
    "\n",
    "preds = mod.predict_generator(test_batches, test_batches.nb_sample)\n",
    "\n",
    "\n",
    "expected_labels = get_expected_labels(test_batches.filenames)\n",
    "my_labels = np.round(iscat)\n",
    "\n",
    "print(preds[:5])\n",
    "print(my_labels[:10])\n",
    "\n",
    "#latest_weights_filename = 'ft%d.h5' % n\n",
    "#mod.save_weights(results_path+ '/' +latest_weights_filename)\n",
    "\n",
    "print (\"Completed %s fit operation\" % n)\n",
    "clean_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "iscat = preds[:, 0]\n",
    "print(preds[:10])\n",
    "filenames = test_batches.filenames\n",
    "print(filenames[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weight files and run on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "onlyfiles = [f for f in listdir(path+'/results/') if isfile(join(path+'/results/', f))]\n",
    "\n",
    "x=[]\n",
    "y_accuracy=[]\n",
    "y_logloss = []\n",
    "gen_test = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "        shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "test_batches = gen_test.flow_from_directory(test_path, batch_size=32)\n",
    "\n",
    "for f in onlyfiles:\n",
    "    mod.load_weights(results_path+'/' + f)\n",
    "    preds = mod.predict_generator(test_batches, test_batches.nb_sample)\n",
    "\n",
    "    filenames = test_batches.filenames\n",
    "\n",
    "    print(filenames[:5])\n",
    "\n",
    "    iscat = preds[:, 0]\n",
    "    my_labels = np.round(iscat)\n",
    "\n",
    "    expected_labels = get_expected_labels(test_batches.filenames)\n",
    "\n",
    "    #     cm = confusion_matrix(expected_labels, my_labels)\n",
    "    #     plot_confusion_matrix(cm, test_batches.class_indices)\n",
    "    k = int(f[2:-3])\n",
    "    #plot k vs training size\n",
    "    #print(expected_labels)\n",
    "    #print(my_labels)\n",
    "\n",
    "    print(accuracy_score(expected_labels, my_labels))\n",
    "    x.append(k)\n",
    "    y_accuracy.append(accuracy_score(expected_labels, my_labels))\n",
    "    y_logloss.append(log_loss(expected_labels, preds))\n",
    "\n",
    "y_accuracy\n",
    "y_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(test_batches.filenames[:5])\n",
    "\n",
    "expected_labels = get_expected_labels(test_batches.filenames)\n",
    "\n",
    "print(expected_labels)\n",
    "\n",
    "#     cm = confusion_matrix(expected_labels, my_labels)\n",
    "#     plot_confusion_matrix(cm, test_batches.class_indices)\n",
    "# k = int(f[2:-3])\n",
    "# #plot k vs training size\n",
    "# print(expected_labels)\n",
    "# print(my_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
