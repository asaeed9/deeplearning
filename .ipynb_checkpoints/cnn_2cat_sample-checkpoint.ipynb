{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.sandbox.cuda): Ignoring call to use(1), GPU number 0 is already in use.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named utils",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dd0aacd5e4c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#path=\"../data/2cat/sample\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileLink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named utils"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "#path=\"../data/2cat/sample\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink\n",
    "from keras.preprocessing import image, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"../data/2cat/sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/deeplearning\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/deeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n"
     ]
    }
   ],
   "source": [
    "%cd ../data/2cat/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a validation set of 2000 random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os, sys\n",
    "# g = glob('*.jpg')\n",
    "# shuf = np.random.permutation(g)\n",
    "# for i in range(2000): os.rename(shuf[i], '../valid/' + shuf[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sample training data, which helps in quickly training/testing a temporary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/asaeed9/work/data/2cat/train'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(1500): copyfile(shuf[i], '../sample/train/' + shuf[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "%mv ../sample/train/dog*.jpg ../sample/train/dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/valid\n"
     ]
    }
   ],
   "source": [
    "%cd ../valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(1000): copyfile(shuf[i], '../sample/valid/' + shuf[i]) \n",
    "%mv ../sample/valid/cat*.jpg ../sample/valid/cats/\n",
    "%mv ../sample/valid/dog*.jpg ../sample/valid/dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/data/2cat/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"/home/asaeed9/work/data/2cat/sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7739ef8e0057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtr_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "\n",
    "tr_batches = gen.flow_from_directory(path + 'train', batch_size=batch_size)\n",
    "val_batches = gen.flow_from_directory(path + 'valid', class_mode='categorical', shuffle=True, batch_size=batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "        Flatten(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 37s - loss: 6.7513 - acc: 0.5493 - val_loss: 7.8817 - val_acc: 0.5110\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 28s - loss: 7.4908 - acc: 0.5233 - val_loss: 8.0752 - val_acc: 0.4990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd50fd8c190>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_6 (BatchNorma (None, 3, 256, 256)   12          batchnormalization_input_5[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 196608)        0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 2)             393218      flatten_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 393,230\n",
      "Trainable params: 393,224\n",
      "Non-trainable params: 6\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with a different learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1500/1500 [==============================] - 28s - loss: 0.9002 - acc: 0.5167 - val_loss: 2.2447 - val_acc: 0.5010\n",
      "Epoch 2/7\n",
      "1500/1500 [==============================] - 21s - loss: 0.7679 - acc: 0.5660 - val_loss: 2.4250 - val_acc: 0.5030\n",
      "Epoch 3/7\n",
      "1500/1500 [==============================] - 21s - loss: 0.7015 - acc: 0.6080 - val_loss: 1.0849 - val_acc: 0.5270\n",
      "Epoch 4/7\n",
      "1500/1500 [==============================] - 22s - loss: 0.6350 - acc: 0.6473 - val_loss: 0.9362 - val_acc: 0.5300\n",
      "Epoch 5/7\n",
      "1500/1500 [==============================] - 22s - loss: 0.6082 - acc: 0.6753 - val_loss: 0.9092 - val_acc: 0.5520\n",
      "Epoch 6/7\n",
      "1500/1500 [==============================] - 21s - loss: 0.5595 - acc: 0.6953 - val_loss: 0.8642 - val_acc: 0.5450\n",
      "Epoch 7/7\n",
      "1500/1500 [==============================] - 22s - loss: 0.5399 - acc: 0.7360 - val_loss: 0.8381 - val_acc: 0.5290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd50cc95150>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "        Flatten(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying another learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 29s - loss: 0.5037 - acc: 0.7540 - val_loss: 0.8212 - val_acc: 0.5470\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 21s - loss: 0.4822 - acc: 0.7827 - val_loss: 0.8633 - val_acc: 0.5460\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 21s - loss: 0.4914 - acc: 0.7687 - val_loss: 0.8373 - val_acc: 0.5260\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 21s - loss: 0.4477 - acc: 0.8013 - val_loss: 0.8411 - val_acc: 0.5400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd50eb3fe90>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking stability of the results depending on the validation-set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "rnd_batches = gen.flow_from_directory(path + 'valid', batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_batches.nb_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78,  0.58],\n",
       "       [ 0.78,  0.58],\n",
       "       [ 0.76,  0.59],\n",
       "       [ 0.77,  0.58],\n",
       "       [ 0.78,  0.59],\n",
       "       [ 0.77,  0.58],\n",
       "       [ 0.79,  0.56],\n",
       "       [ 0.77,  0.59],\n",
       "       [ 0.78,  0.58],\n",
       "       [ 0.8 ,  0.59]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_res = [model.evaluate_generator(rnd_batches, rnd_batches.nb_sample) for i in range(10)]\n",
    "np.round(val_res, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 28s - loss: 1.6714 - acc: 0.5353 - val_loss: 4.4303 - val_acc: 0.5230\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 22s - loss: 1.1132 - acc: 0.6327 - val_loss: 2.6965 - val_acc: 0.5020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4ffa59c90>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "        Flatten(),\n",
    "        Dense(2, activation='softmax', W_regularizer=l2(0.01))\n",
    "    ])\n",
    "model.compile(Adam(lr=10e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 28s - loss: 0.7129 - acc: 0.7233 - val_loss: 1.5265 - val_acc: 0.5490\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 22s - loss: 0.7995 - acc: 0.7167 - val_loss: 2.2433 - val_acc: 0.5170\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 21s - loss: 0.6981 - acc: 0.7327 - val_loss: 1.7602 - val_acc: 0.5700\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 21s - loss: 0.4783 - acc: 0.8120 - val_loss: 1.5426 - val_acc: 0.5420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd50cc22390>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 28s - loss: 0.8613 - acc: 0.5627 - val_loss: 4.2089 - val_acc: 0.5230\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 21s - loss: 0.5745 - acc: 0.6987 - val_loss: 1.4782 - val_acc: 0.5670\n",
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 28s - loss: 0.4532 - acc: 0.7960 - val_loss: 1.6948 - val_acc: 0.5130\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 22s - loss: 0.4246 - acc: 0.8147 - val_loss: 1.2864 - val_acc: 0.5330\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 21s - loss: 0.3514 - acc: 0.8713 - val_loss: 0.9073 - val_acc: 0.5890\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 21s - loss: 0.2809 - acc: 0.9133 - val_loss: 0.8055 - val_acc: 0.5900\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 21s - loss: 0.2380 - acc: 0.9313 - val_loss: 0.7803 - val_acc: 0.5790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4ff9d29d0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "model.optimizer.lr = 0.01\n",
    "model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=5, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 29s - loss: 0.8577 - acc: 0.6853 - val_loss: 0.9611 - val_acc: 0.5360\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 22s - loss: 0.3675 - acc: 0.8447 - val_loss: 0.6687 - val_acc: 0.5920\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 29s - loss: 0.1496 - acc: 0.9627 - val_loss: 0.7606 - val_acc: 0.5240\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 22s - loss: 0.0853 - acc: 0.9900 - val_loss: 0.7999 - val_acc: 0.5260\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 22s - loss: 0.0454 - acc: 0.9980 - val_loss: 0.8097 - val_acc: 0.5440\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 22s - loss: 0.0292 - acc: 0.9980 - val_loss: 0.9052 - val_acc: 0.5470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7fd50eb3fed0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1(tr_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(width_shift_range=0.1)\n",
    "tr_batches = gen.flow_from_directory(path + 'train', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 29s - loss: 1.0107 - acc: 0.6167 - val_loss: 1.1643 - val_acc: 0.5010\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 22s - loss: 0.5162 - acc: 0.7547 - val_loss: 0.6898 - val_acc: 0.5720\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 29s - loss: 0.3925 - acc: 0.8267 - val_loss: 0.9053 - val_acc: 0.5450\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 22s - loss: 0.3353 - acc: 0.8667 - val_loss: 0.8652 - val_acc: 0.5330\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 22s - loss: 0.2803 - acc: 0.8873 - val_loss: 0.8740 - val_acc: 0.5410\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 22s - loss: 0.2632 - acc: 0.8993 - val_loss: 0.9044 - val_acc: 0.5420\n"
     ]
    }
   ],
   "source": [
    "model = conv1(tr_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(channel_shift_range=20)\n",
    "tr_batches = gen.flow_from_directory(path + 'train', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 29s - loss: 0.9852 - acc: 0.6240 - val_loss: 1.6840 - val_acc: 0.5220\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 22s - loss: 0.4016 - acc: 0.8233 - val_loss: 0.6654 - val_acc: 0.6010\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 30s - loss: 0.2525 - acc: 0.9087 - val_loss: 0.6827 - val_acc: 0.5780\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 23s - loss: 0.1727 - acc: 0.9527 - val_loss: 0.6959 - val_acc: 0.5980\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 23s - loss: 0.1207 - acc: 0.9747 - val_loss: 0.8599 - val_acc: 0.5420\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 23s - loss: 0.0815 - acc: 0.9840 - val_loss: 0.9064 - val_acc: 0.5500\n"
     ]
    }
   ],
   "source": [
    "model = conv1(tr_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "tr_batches = gen.flow_from_directory(path + 'train', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 29s - loss: 1.0994 - acc: 0.5880 - val_loss: 3.1034 - val_acc: 0.5060\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 22s - loss: 0.3986 - acc: 0.8300 - val_loss: 1.3480 - val_acc: 0.5170\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 29s - loss: 0.2187 - acc: 0.9227 - val_loss: 0.9061 - val_acc: 0.5450\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 23s - loss: 0.1426 - acc: 0.9573 - val_loss: 0.8089 - val_acc: 0.5680\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 22s - loss: 0.0844 - acc: 0.9860 - val_loss: 0.8863 - val_acc: 0.5710\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 22s - loss: 0.0502 - acc: 0.9960 - val_loss: 0.9572 - val_acc: 0.5790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7fd4ede65290>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1(tr_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on a smaller learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 30s - loss: 0.0619 - acc: 0.9887 - val_loss: 0.8665 - val_acc: 0.5910\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 23s - loss: 0.0455 - acc: 0.9947 - val_loss: 1.0434 - val_acc: 0.5770\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 22s - loss: 0.0323 - acc: 0.9940 - val_loss: 1.0761 - val_acc: 0.5730\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 23s - loss: 0.0226 - acc: 0.9973 - val_loss: 1.0535 - val_acc: 0.6010\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 22s - loss: 0.0205 - acc: 0.9987 - val_loss: 1.0348 - val_acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4f1da5c50>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=5, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run for 25 epochs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.0185 - acc: 0.9973 - val_loss: 0.9863 - val_acc: 0.6160\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0118 - acc: 1.0000 - val_loss: 0.9414 - val_acc: 0.6340\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0091 - acc: 0.9993 - val_loss: 0.9093 - val_acc: 0.6400\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.9842 - val_acc: 0.6210\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.9559 - val_acc: 0.6410\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.8769 - val_acc: 0.6680\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.8978 - val_acc: 0.6610\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 23s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8696 - val_acc: 0.6780\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.8921 - val_acc: 0.6840\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.8162 - val_acc: 0.6910\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 23s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.9146 - val_acc: 0.6720\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.6960\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.8923 - val_acc: 0.6900\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.8758 - val_acc: 0.6910\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.8978 - val_acc: 0.6920\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9343 - val_acc: 0.6910\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.9003 - val_acc: 0.6880\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9029 - val_acc: 0.6990\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 23s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.9609 - val_acc: 0.6960\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 23s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9091 - val_acc: 0.6830\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9354 - val_acc: 0.6960\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9072 - val_acc: 0.6860\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 23s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9854 - val_acc: 0.6960\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 22s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9160 - val_acc: 0.7000\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 22s - loss: 7.6719e-04 - acc: 1.0000 - val_loss: 0.8928 - val_acc: 0.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4f1da5110>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=25, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
