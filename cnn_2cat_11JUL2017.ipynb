{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/deeplearning\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/deeplearning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda\n",
    "#cuda.use('gpu1')\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "#path=\"../data/2cat/sample\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink\n",
    "from keras.preprocessing import image, sequence\n",
    "import os, sys, cv2\n",
    "from shutil import copyfile, move\n",
    "import os\n",
    "####\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/home/asaeed9/work/data/2cat\"\n",
    "data_src = \"sample\"\n",
    "path=\"/home/asaeed9/work/data/2cat/\" + data_src + \"/\"\n",
    "results_path = \"/home/asaeed9/work/data/2cat/\"+ data_src+\"/results\"\n",
    "test_path = path + '/test/' #We use all the test data\n",
    "os.chdir(\"/home/asaeed9/work/data/2cat/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grey images - minimal image augmentation\n",
    "\n",
    "#clean previous data\n",
    "def adjust_prev_data_sample(dest):\n",
    "    move_files(path + \"train/cats\", data_dir + \"/\" + dest, \"*\")\n",
    "    move_files(path + \"train/dogs\", data_dir + \"/\" + dest, \"*\")\n",
    "    move_files(path + \"valid/cats\", data_dir + \"/\" + dest, \"*\")\n",
    "    move_files(path + \"valid/dogs\", data_dir + \"/\" + dest, \"*\")\n",
    "    \n",
    "#clean previous data\n",
    "def adjust_prev_data(dest):\n",
    "    move_files(data_dir + \"/valid\", data_dir + \"/\" + dest, \"*\")\n",
    "    move_files(data_dir + \"/used_train\", data_dir + \"/\" + dest, \"*\")\n",
    "    # %mv $data_dir/valid/* $data_dir/train/\n",
    "    adjust_prev_data_sample(dest)\n",
    "\n",
    "def copy_samples(train, validation, remove_existing):\n",
    "    #print(\"Copying new samples for training...\")\n",
    "    #clean previous data\n",
    "    if remove_existing:\n",
    "        print(\"Adjusting previous data...\")\n",
    "        adjust_prev_data(\"train\")\n",
    "\n",
    "    #build validation set\n",
    "#     g = glob('*.jpg')\n",
    "#     shuf = np.random.permutation(g)\n",
    "#     for i in range(validation): os.rename(shuf[i], '../valid/' + shuf[i])\n",
    "\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(train): os.rename(shuf[i], \"../\" + data_src + \"/train/\" + shuf[i])\n",
    "    move_files(path + \"train\",path + \"train/cats/\",\"cat*.jpg\")\n",
    "    move_files(path + \"train\",path + \"train/dogs/\",\"dog*.jpg\")\n",
    "\n",
    "    # %mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "    # %mv ../sample/train/dog*.jpg ../sample/train/dogs/\n",
    "#     os.chdir(\"../valid\")\n",
    "    #%cd ../valid\n",
    "\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(validation): os.rename(shuf[i], \"../\" + data_src + \"/valid/\" + shuf[i])\n",
    "\n",
    "    move_files(path + \"valid\",path + \"valid/cats/\",\"cat*.jpg\")\n",
    "    move_files(path + \"valid\",path + \"valid/dogs/\",\"dog*.jpg\")\n",
    "    #os.chdir(data_dir + \"/train\")\n",
    "    \n",
    "    #print(os.listdir(path+\"train/dogs/\"))\n",
    "    dog_train_count = get_file_count(path + \"train/dogs/\") \n",
    "    dog_valid_count = get_file_count(path + \"valid/dogs/\")\n",
    "\n",
    "    cat_train_count = get_file_count(path + \"train/cats/\") \n",
    "    cat_valid_count = get_file_count(path + \"valid/cats/\")\n",
    "    \n",
    "    return dog_train_count, dog_valid_count, cat_train_count, cat_valid_count\n",
    "\n",
    "# def adjust_prev_data():\n",
    "#     %mv $data_dir/valid/* $data_dir/train/\n",
    "    \n",
    "#     %rm $path/train/cats/*\n",
    "#     %rm $path/train/dogs/*\n",
    "#     %rm $path/valid/cats/*\n",
    "#     %rm $path/valid/dogs/*\n",
    "\n",
    "def move_files(src_path, dest_path, pattern):\n",
    "    for file in glob(src_path + '/' + pattern):\n",
    "        try:\n",
    "                move(os.path.join(src_path+'/', os.path.basename(file)), os.path.join(dest_path+'/',os.path.basename(file)))\n",
    "        except IOError, e:\n",
    "                print (\"Unable to move file. \".format(e))\n",
    "\n",
    "def get_file_count(dir_path):\n",
    "    return len([name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path,name))])\n",
    "\n",
    "#copy training images\n",
    "# def copy_samples(train, validation):\n",
    "    \n",
    "#     #clean previous data\n",
    "#     adjust_prev_data(\"train\")\n",
    "    \n",
    "#     #build validation set\n",
    "#     g = glob('*.jpg')\n",
    "#     shuf = np.random.permutation(g)\n",
    "#     for i in range(validation): os.rename(shuf[i], '../valid/' + shuf[i]) \n",
    "    \n",
    "#     g = glob('*.jpg')\n",
    "#     shuf = np.random.permutation(g)\n",
    "#     for i in range(train): copyfile(shuf[i], '../sample/train/' + shuf[i]) \n",
    "#     %mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "#     %mv ../sample/train/dog*.jpg ../sample/train/dogs/\n",
    "    \n",
    "#     %cd ../valid\n",
    "\n",
    "#     g = glob('*.jpg')\n",
    "#     shuf = np.random.permutation(g)\n",
    "#     for i in range(validation): copyfile(shuf[i], '../sample/valid/' + shuf[i]) \n",
    "#     %mv ../sample/valid/cat*.jpg ../sample/valid/cats/\n",
    "#     %mv ../sample/valid/dog*.jpg ../sample/valid/dogs/\n",
    "#     %cd $data_dir/train\n",
    "\n",
    "\n",
    "def onehot(x): return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())\n",
    "\n",
    "def predict(path, model, predict_type):\n",
    "    gen_test = image.ImageDataGenerator()\n",
    "    test_batches = gen_test.flow_from_directory(path+predict_type, class_mode=None, target_size=(256,256), shuffle=False, batch_size=1)\n",
    "    test_data = np.concatenate([test_batches.next() for i in range(test_batches.nb_sample)])\n",
    "    test_labels = onehot(test_batches.classes)\n",
    "    score = model.evaluate(test_data, test_labels)\n",
    "    \n",
    "    probs = model.predict(test_data)\n",
    "    \n",
    "    #loss_score.append(score[0])\n",
    "    #accuracy_score.append(score[1])\n",
    "    \n",
    "    #print(\"\\nLoss:{}, Accuracy:{}\".format(score[0], score[1]))\n",
    "    #print(\"\\nProbabilities:{}\".format(probs))\n",
    "    return probs, test_batches, score[0], score[1]\n",
    "\n",
    "def pred_batch(imgs, classes):\n",
    "    preds = model.predict(imgs)\n",
    "    idxs = np.argmax(preds, axis=1)\n",
    "\n",
    "    print('Shape: {}'.format(preds.shape))\n",
    "    print('First 5 classes: {}'.format(classes[:5]))\n",
    "    print('First 5 probabilities: {}\\n'.format(preds[:5]))\n",
    "    print('Predictions prob/class: ')\n",
    "    \n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        print ('  {:.4f}/{}'.format(preds[i, idx], classes[idx]))\n",
    "\n",
    "\n",
    "def generate_size_graph(fig_no, training_size, accuracy, loss, start_size, end_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(training_size,accuracy)\n",
    "    plt.plot(training_size,loss)\n",
    "    plt.xlabel('Training Size')\n",
    "    plt.ylabel('Accuracy/Loss')\n",
    "    plt.title('Training Size vs Accuracy/Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['Accuracy','Loss'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(path + '/batch_graphs/' +  str(start_size) + '_' + str(end_size) + '.jpg') \n",
    "        \n",
    "def generate_graph(fig_no, epochs, train, val, label, train_title, val_title, train_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(epochs,train)\n",
    "    plt.plot(epochs,val)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel(label)\n",
    "    plt.title(train_title + ' vs ' + val_title + '( Samples:' + str(train_size) + ')')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(results_path + '/batch_graphs/' +  label + '_' + str(train_size) + '.jpg') \n",
    "    \n",
    "def get_train_model(tr_batches, val_batches, epoch):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3, 256,256)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "#             Convolution2D(64,3,3, activation='relu'),\n",
    "#             BatchNormalization(axis=1),\n",
    "            #MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Flatten(),\n",
    "            Dense(1024, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=epoch - 2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model\n",
    "\n",
    "def train_model(model, tr_batches, val_batches, epoch):\n",
    "    if not model:\n",
    "        model = Sequential([\n",
    "                BatchNormalization(axis=1, input_shape=(3, 256,256)),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Dropout(0.2),\n",
    "    #             Convolution2D(64,3,3, activation='relu'),\n",
    "    #             BatchNormalization(axis=1),\n",
    "                #MaxPooling2D((3,3)),\n",
    "                Convolution2D(64,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Dropout(0.2),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Dropout(0.2),\n",
    "                Flatten(),\n",
    "                Dense(1024, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dropout(0.2),\n",
    "                Dense(2, activation='softmax')\n",
    "            ])\n",
    "        model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches,\n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=1, validation_data=val_batches,\n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=epoch - 3, validation_data=val_batches,\n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit(old_model, path, results_path, nepoch, batch_size, train_size, valid_size):\n",
    "    gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05,\n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "\n",
    "    #for train in training_range:\n",
    "    model = None\n",
    "    if old_model:\n",
    "        dog_train_count, dog_valid_count, cat_train_count, cat_valid_count = copy_samples(train_size, valid_size, False)\n",
    "\n",
    "        print(\"Train + Valid Dogs: {} \\n Train + Valid Cats: {}\".format(dog_train_count + \n",
    "                                                                        dog_valid_count,  \n",
    "                                                                        cat_train_count + \n",
    "                                                                        cat_valid_count))  \n",
    "    else:\n",
    "        print(\"First iteration...\")\n",
    "        dog_train_count, dog_valid_count, cat_train_count, cat_valid_count = copy_samples(train_size, valid_size, True)\n",
    "\n",
    "        print(\"Train + Valid Dogs: {} \\n Train + Valid Cats: {}\".format(dog_train_count + \n",
    "                                                                        dog_valid_count,  \n",
    "                                                                        cat_train_count + \n",
    "                                                                        cat_valid_count))  \n",
    "    \n",
    "        \n",
    "    tr_batches = gen_t.flow_from_directory(path + 'train', batch_size=batch_size)\n",
    "    val_batches = gen_t.flow_from_directory(path + 'valid', class_mode='categorical', \n",
    "                                            shuffle=True, batch_size=batch_size * 2)\n",
    "\n",
    "    if old_model:\n",
    "        model = train_model(old_model, tr_batches, val_batches, nepoch)\n",
    "    else:\n",
    "        model = train_model(None, tr_batches, val_batches, nepoch)\n",
    "\n",
    "    #model.summary()\n",
    "    \n",
    "    #model.save_weights(results_path+ '/' + 'ft_' + str(train_size) + '.e' + str(nepoch))\n",
    "    last_file_timestamp = '{:%Y%m%d%H%M%S}'.format(datetime.datetime.now())\n",
    "    #print('File Time Stamp:{}'.format(last_file_timestamp))\n",
    "    model.save_weights(results_path+'/ft_{}'.format(last_file_timestamp))\n",
    "    #model.load_weights(results_path+'/ft_{}'.format(last_file_timestamp))\n",
    "\n",
    "    return model, last_file_timestamp\n",
    "\n",
    "\n",
    "def get_test_model():\n",
    "    model = Sequential([\n",
    "                BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "    #             Convolution2D(64,3,3, activation='relu'),\n",
    "    #             BatchNormalization(axis=1),\n",
    "                #MaxPooling2D((3,3)),\n",
    "                Convolution2D(64,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Flatten(),\n",
    "                Dense(1024, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dense(2, activation='softmax')\n",
    "            ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 100\n",
      "Valid size: 20\n",
      "First iteration...\n",
      "Adjusting previous data...\n",
      "[]\n",
      "Path: /home/asaeed9/work/data/2cat/sample/train/dogs/, File Count: 53\n",
      "Train + Valid Dogs: 63 \n",
      " Train + Valid Cats: 57\n",
      "Found 100 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-45d3f7e732c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     tr_model,file_timestamp = fit(tr_model, path, results_path, nepoch, \n\u001b[0;32m---> 30\u001b[0;31m                                   batch_size, train_size, valid_size)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nVerification on Test set.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-87a83402f498>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(old_model, path, results_path, nepoch, batch_size, train_size, valid_size)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-87a83402f498>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, tr_batches, val_batches, epoch)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches,\n\u001b[0;32m--> 223\u001b[0;31m                      nb_val_samples=val_batches.nb_sample)\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m                                              \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                                              \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                                              **self._function_kwargs)\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Invalid argument \"%s\" passed to K.function'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m                                         \u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1792\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m             defaults)\n\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                         optimizer, inputs, outputs)\n\u001b[1;32m   1473\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                     \u001b[0moptimizer_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnb_nodes_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0msub_prof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnb_nodes_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0msub_prof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph, start_from)\u001b[0m\n\u001b[1;32m   2468\u001b[0m                         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_imported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m                         \u001b[0mt_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m                         \u001b[0mlopt_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m                         \u001b[0mtime_opts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlopt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlopt_change\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(self, fgraph, node, lopt)\u001b[0m\n\u001b[1;32m   1980\u001b[0m         \u001b[0mlopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlopt\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m             \u001b[0mreplacements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailure_callback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/opt.pyc\u001b[0m in \u001b[0;36mlocal_gpu_downsample_factor_max_grad\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \u001b[0mnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_constant_args_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/opt.pyc\u001b[0m in \u001b[0;36m_check_constant_args_pool\u001b[0;34m(ndim, ws, stride, pad, node)\u001b[0m\n\u001b[1;32m   1862\u001b[0m     \u001b[0;34m\"\"\"Check if the args of pool are constants. Warns if not.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m         \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scalar_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scalar_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scalar_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/opt.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((i,))\u001b[0m\n\u001b[1;32m   1862\u001b[0m     \u001b[0;34m\"\"\"Check if the args of pool are constants. Warns if not.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m         \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scalar_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scalar_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scalar_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/tensor/var.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    577\u001b[0m                     self, *theano.tensor.subtensor.Subtensor.collapse(\n\u001b[1;32m    578\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                         lambda entry: isinstance(entry, Variable)))\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \"\"\"\n\u001b[1;32m    614\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'off'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/tensor/subtensor.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(self, x, *inputs)\u001b[0m\n\u001b[1;32m    522\u001b[0m                          \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                          [theano.tensor.tensor(dtype=x.type.dtype,\n\u001b[0;32m--> 524\u001b[0;31m                                                broadcastable=broadcastable)])\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/tensor/basic.pyc\u001b[0m in \u001b[0;36mtensor\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asaeed9/anaconda2/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dtype, broadcastable, name, sparse_grad)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# broadcastable is immutable, and all elements are either\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# True or False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcastable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbroadcastable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# error checking is done there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir(data_dir + \"/train\") \n",
    "training_set_size = []\n",
    "loss_array = []\n",
    "accuracy_array = []\n",
    "loss=0.0\n",
    "accuracy=0.0\n",
    "nepoch = 5\n",
    "batch_size = 64\n",
    "training_range = range(100, 30000, 2000)\n",
    "tr_model = None\n",
    "#%rm $path/results/*\n",
    "\n",
    "for train_size in training_range:\n",
    "    model = None\n",
    "    #train = 15000\n",
    "    valid_size = int(math.floor(.2 * train_size))\n",
    "    print('Train size: {}'.format(train_size))\n",
    "    print('Valid size: {}'.format(valid_size))\n",
    "    \n",
    "#    copy_samples(train, valid)\n",
    "\n",
    "#     tr_batches = gen_t.flow_from_directory(path + 'train', batch_size=batch_size)\n",
    "#     val_batches = gen_t.flow_from_directory(path + 'valid', class_mode='categorical', shuffle=True, batch_size=batch_size * 2)\n",
    "\n",
    "#     model = get_train_model(tr_batches, val_batches, nepoch)\n",
    "    \n",
    "#     model.save_weights(results_path+ '/' + 'ft_' + str(train) + '.e' + str(nepoch))\n",
    "\n",
    "    tr_model,file_timestamp = fit(tr_model, path, results_path, nepoch, \n",
    "                                  batch_size, train_size, valid_size)\n",
    "    \n",
    "    print(\"\\nVerification on Test set.\")\n",
    "    model_test = None\n",
    "    model_test = get_test_model()\n",
    "    #model.load_weights(results_path+'/ft_' + str(train_size) + '.e' + str(nepoch))\n",
    "    #print('{0}/ft_{1}'.format(last_file_timestamp))\n",
    "    #print('Last File Timestamp- before loading:{}'.format(file_timestamp))\n",
    "    model_test.load_weights(results_path+'/ft_{}'.format(file_timestamp))\n",
    "\n",
    "    probs, test_batches,loss, accuracy = predict(path, model_test, \"test\")\n",
    "    training_set_size.append(train_size)\n",
    "    loss_array.append(loss)\n",
    "    accuracy_array.append(accuracy)\n",
    "\n",
    "    print('\\nTraining Set Size:{}'.format(training_set_size))\n",
    "    print('Accuracy:{}'.format(accuracy_array))\n",
    "    print('Loss:{}'.format(loss_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_range = range(3000, 18001, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "model = get_test_model()\n",
    "loss_score = []\n",
    "accuracy_score = []\n",
    "training_size = training_range\n",
    "\n",
    "os.chdir(results_path)\n",
    "files = filter(os.path.isfile, os.listdir(results_path))\n",
    "files.sort(key=lambda x: os.path.getmtime(x))\n",
    "\n",
    "for f in files:\n",
    "    \n",
    "    print(\"\\nFile being processed: {}\".format(f))\n",
    "    \n",
    "    train_size = int(f[f.find('_')+1 : f.find('.')])\n",
    "    epoch = int(f[f.find('e')+1 : ])\n",
    "\n",
    "    model.load_weights(results_path+'/ft_' + str(train_size) + '.e' + str(epoch))\n",
    "    \n",
    "    gen_test = image.ImageDataGenerator()\n",
    "    test_batches = gen_test.flow_from_directory(path+'test', class_mode=None, target_size=(256,256), shuffle=False, batch_size=1)\n",
    "    test_data = np.concatenate([test_batches.next() for i in range(test_batches.nb_sample)])\n",
    "    test_labels = onehot(test_batches.classes)\n",
    "    score = model.evaluate(test_data, test_labels)\n",
    "    \n",
    "    loss_score.append(score[0])\n",
    "    accuracy_score.append(score[1])\n",
    "    \n",
    "    print(\"\\nLoss:{}, Accuracy:{}\".format(score[0], score[1]))\n",
    "\n",
    "#print(loss_score, accuracy_score)\n",
    "#fig_no, training_size, accuracy, loss, start_size, end_size\n",
    "generate_size_graph(1, training_size, accuracy_score, loss_score, min(training_size), max(training_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_size = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1500, 2000, 2500, 3000, 6000, 9000, 12000, 15000, 18000]\n",
    "accuracy_score = [0.53033,0.53033,0.648333, 0.569333, 0.638666, 0.59800, 0.6416667, 0.7143333, 0.6746667, 0.6569999,0.6846667, 0.6756667, 0.7140000, 0.7703333,  0.82533, 0.871, 0.87966, 0.920333, 0.924]\n",
    "loss_score = [1.77806968212, 2.08722846731, 1.21485737689, 1.99998559408, 1.04420828152, 1.76575960827, 1.2628258756, 0.975768786112, 1.28816328855, 1.22704125532, 1.395495, 1.239842, 0.921525, 0.7399451, 0.580999, 0.342369, 0.33888, 0.233011, 0.2023495]\n",
    "\n",
    "print(len(training_size), len(accuracy_score), len(loss_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_size_graph(1, training_size, accuracy_score, loss_score, min(training_size), max(training_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_images(data_path):\n",
    "    data_dir_list = os.listdir(data_path)\n",
    "    img_data_list=[]\n",
    "    labels=[]\n",
    "\n",
    "    for dataset in data_dir_list:\n",
    "        img_list=os.listdir(data_path+'/'+ dataset)\n",
    "        print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "        for img in img_list:\n",
    "\n",
    "            if 'cat' in img:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "            input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "            #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "            print(type(input_img), input_img.shape)\n",
    "            input_img_resize=cv2.resize(input_img,(256,256))\n",
    "            print(type(input_img_resize), input_img_resize.shape)\n",
    "            exit(1)\n",
    "            img_data_list.append(input_img_resize)\n",
    "\n",
    "    img_data = np.array(img_data_list)\n",
    "    img_data = img_data.astype('float32')\n",
    "    return img_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img_data, test_labels = get_numpy_images(test_path)\n",
    "#test_img_data = np.expand_dims(test_img_data, axis=1)\n",
    "test_nsamples = test_img_data.shape[0]\n",
    "test_input_shape=test_img_data[0].shape\n",
    "\n",
    "test_Y = np_utils.to_categorical(test_labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(test_img_data, test_Y, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filenames = test_batches.filenames\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "print(filenames[:10])\n",
    "print(preds[:10])\n",
    "#our_labels = np.round(preds[:, 0])\n",
    "#our_labels[:10]\n",
    "#our_preds = preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(preds[:10])\n",
    "filenames = test_batches.filenames\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_labels = get_test_labels(test_batches.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
