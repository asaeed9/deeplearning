{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/deeplearning\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/deeplearning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "ERROR (theano.sandbox.cuda): ERROR: Not using GPU. Initialisation of device 1 failed:\n",
      "Bad device number 1. Only 1 devices available.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN 5105)\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.sandbox.cuda): Ignoring call to use(1), GPU number 0 is already in use.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "#path=\"../data/2cat/sample\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink\n",
    "from keras.preprocessing import image, sequence\n",
    "import os, sys\n",
    "from shutil import copyfile\n",
    "\n",
    "####\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"/home/asaeed9/work/data/2cat/sample/\"\n",
    "results_path = \"/home/asaeed9/work/data/2cat/sample/results\"\n",
    "test_path = path + '/test/' #We use all the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n"
     ]
    }
   ],
   "source": [
    "%cd ../data/2cat/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy training images\n",
    "def copy_samples(n):\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(n): copyfile(shuf[i], '../sample/train/' + shuf[i]) \n",
    "    %mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "    %mv ../sample/train/dog*.jpg ../sample/train/dogs/\n",
    "    \n",
    "    %cd ../valid\n",
    "\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(500): copyfile(shuf[i], '../sample/valid/' + shuf[i]) \n",
    "    %mv ../sample/valid/cat*.jpg ../sample/valid/cats/\n",
    "    %mv ../sample/valid/dog*.jpg ../sample/valid/dogs/\n",
    "    %cd /home/asaeed9/work/data/2cat/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_up():\n",
    "    %rm $path/train/cats/*\n",
    "    %rm $path/train/dogs/*\n",
    "    %rm $path/valid/cats/*\n",
    "    %rm $path/valid/dogs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n",
      "sample size: 1500\n",
      "/home/asaeed9/work/data/2cat/valid\n",
      "/home/asaeed9/work/data/2cat/train\n"
     ]
    }
   ],
   "source": [
    "%cd /home/asaeed9/work/data/2cat/train\n",
    "#for n in range(1000, 5001, 1000):\n",
    "n = 1500\n",
    "print('sample size: {}'.format(n))\n",
    "copy_samples(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "#             Convolution2D(64,3,3, activation='relu'),\n",
    "#             BatchNormalization(axis=1),\n",
    "            #MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Flatten(),\n",
    "            Dense(1024, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "#                      nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=50, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "\n",
    "tr_batches = gen_t.flow_from_directory(path + 'train', batch_size=batch_size)\n",
    "val_batches = gen_t.flow_from_directory(path + 'valid', class_mode='categorical', shuffle=True, batch_size=batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 28s - loss: 1.2398 - acc: 0.5813 - val_loss: 2.1502 - val_acc: 0.4900\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 27s - loss: 0.7863 - acc: 0.6020 - val_loss: 1.6568 - val_acc: 0.4980\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 30s - loss: 0.7426 - acc: 0.6260 - val_loss: 1.7099 - val_acc: 0.4820\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.6616 - acc: 0.6493 - val_loss: 0.9976 - val_acc: 0.5820\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.6466 - acc: 0.6640 - val_loss: 0.8389 - val_acc: 0.6700\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.6149 - acc: 0.6840 - val_loss: 1.3903 - val_acc: 0.5700\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.5838 - acc: 0.7060 - val_loss: 0.7206 - val_acc: 0.7020\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.5738 - acc: 0.7107 - val_loss: 0.7307 - val_acc: 0.6760\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.5844 - acc: 0.6933 - val_loss: 0.8981 - val_acc: 0.6460\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 30s - loss: 0.5408 - acc: 0.7287 - val_loss: 0.5945 - val_acc: 0.7480\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 32s - loss: 0.5779 - acc: 0.7287 - val_loss: 0.5799 - val_acc: 0.7200\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.5543 - acc: 0.7273 - val_loss: 0.6038 - val_acc: 0.7260\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 24s - loss: 0.4975 - acc: 0.7693 - val_loss: 0.5658 - val_acc: 0.7440\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 28s - loss: 0.5259 - acc: 0.7400 - val_loss: 0.5872 - val_acc: 0.7420\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.4853 - acc: 0.7707 - val_loss: 0.5445 - val_acc: 0.7680\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.4892 - acc: 0.7720 - val_loss: 0.5221 - val_acc: 0.7680\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.4925 - acc: 0.7687 - val_loss: 0.7212 - val_acc: 0.6900\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 27s - loss: 0.5072 - acc: 0.7547 - val_loss: 0.7151 - val_acc: 0.7100\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.5124 - acc: 0.7593 - val_loss: 0.5257 - val_acc: 0.7660\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.4644 - acc: 0.7860 - val_loss: 0.4373 - val_acc: 0.7820\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.4766 - acc: 0.7793 - val_loss: 0.4869 - val_acc: 0.7860\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.4542 - acc: 0.7960 - val_loss: 0.5199 - val_acc: 0.7520\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 27s - loss: 0.4686 - acc: 0.7873 - val_loss: 0.4789 - val_acc: 0.8000\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.4543 - acc: 0.7920 - val_loss: 0.5561 - val_acc: 0.7800\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 30s - loss: 0.4396 - acc: 0.7867 - val_loss: 0.6197 - val_acc: 0.7260\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 29s - loss: 0.4375 - acc: 0.8000 - val_loss: 0.6748 - val_acc: 0.7220\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 29s - loss: 0.4115 - acc: 0.8073 - val_loss: 0.5265 - val_acc: 0.7460\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.4370 - acc: 0.7933 - val_loss: 0.5915 - val_acc: 0.7440\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.4439 - acc: 0.7967 - val_loss: 0.5912 - val_acc: 0.7400\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.4273 - acc: 0.7933 - val_loss: 0.4736 - val_acc: 0.7940\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.4075 - acc: 0.8233 - val_loss: 0.6304 - val_acc: 0.7260\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.3910 - acc: 0.8307 - val_loss: 0.4140 - val_acc: 0.7940\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.4286 - acc: 0.8100 - val_loss: 0.4504 - val_acc: 0.8000\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.3735 - acc: 0.8260 - val_loss: 0.4777 - val_acc: 0.8080\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.3905 - acc: 0.8267 - val_loss: 0.4906 - val_acc: 0.7800\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 30s - loss: 0.3779 - acc: 0.8207 - val_loss: 0.4566 - val_acc: 0.7900\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.3661 - acc: 0.8320 - val_loss: 0.6083 - val_acc: 0.7700\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.3893 - acc: 0.8327 - val_loss: 0.4903 - val_acc: 0.7680\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 30s - loss: 0.3774 - acc: 0.8360 - val_loss: 0.4428 - val_acc: 0.7940\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.3502 - acc: 0.8527 - val_loss: 0.4879 - val_acc: 0.7980\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 28s - loss: 0.3899 - acc: 0.8313 - val_loss: 0.4961 - val_acc: 0.7920\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 30s - loss: 0.3297 - acc: 0.8600 - val_loss: 0.4517 - val_acc: 0.8160\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.3309 - acc: 0.8607 - val_loss: 0.5593 - val_acc: 0.7480\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.3633 - acc: 0.8380 - val_loss: 0.4835 - val_acc: 0.7960\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 24s - loss: 0.3442 - acc: 0.8567 - val_loss: 0.4387 - val_acc: 0.8100.85\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 31s - loss: 0.3541 - acc: 0.8487 - val_loss: 0.5419 - val_acc: 0.7480\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.3530 - acc: 0.8573 - val_loss: 0.4555 - val_acc: 0.7980\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 27s - loss: 0.3608 - acc: 0.8447 - val_loss: 0.4480 - val_acc: 0.8240\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 26s - loss: 0.3204 - acc: 0.8627 - val_loss: 0.5073 - val_acc: 0.7920\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 25s - loss: 0.3234 - acc: 0.8500 - val_loss: 0.4667 - val_acc: 0.8020\n"
     ]
    }
   ],
   "source": [
    "model = conv1(tr_batches)\n",
    "model.save_weights(results_path+ '/' +'ft_15000.e50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_test = image.ImageDataGenerator()\n",
    "test_batches = gen_test.flow_from_directory(test_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'axis' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1c4961c7d22b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/ft_15000.e50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'axis' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "#             Convolution2D(64,3,3, activation='relu'),\n",
    "#             BatchNormalization(axis=1),\n",
    "            #MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(1024, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "model.load_weights(results_path+'/ft_15000.e50')    \n",
    "preds = model.predict(np.array(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9899  0.0101]\n",
      " [ 0.0016  0.9984]\n",
      " [ 0.0097  0.9903]\n",
      " [ 0.1045  0.8955]\n",
      " [ 0.003   0.997 ]\n",
      " [ 0.985   0.015 ]\n",
      " [ 0.6525  0.3475]\n",
      " [ 0.3544  0.6456]\n",
      " [ 0.9281  0.0719]\n",
      " [ 0.9812  0.0188]]\n",
      "['cats/cat.10923.jpg', 'cats/cat.12414.jpg', 'cats/cat.6013.jpg', 'cats/cat.2881.jpg', 'cats/cat.2445.jpg', 'cats/cat.11129.jpg', 'cats/cat.359.jpg', 'cats/cat.9922.jpg', 'cats/cat.12013.jpg', 'cats/cat.701.jpg']\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(preds[:10])\n",
    "print(test_batches.filenames[:10])\n",
    "print(test_batches.classes[:10])\n",
    "#is dog\n",
    "# print(preds[:10])\n",
    "# y_pred = np.argmax(preds, axis=1)\n",
    "#y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unknown/cat.10923.jpg', 'unknown/dog.571.jpg', 'unknown/cat.12414.jpg', 'unknown/cat.6013.jpg', 'unknown/cat.2881.jpg', 'unknown/dog.3678.jpg', 'unknown/cat.2445.jpg', 'unknown/cat.11129.jpg', 'unknown/cat.359.jpg', 'unknown/cat.9922.jpg']\n",
      "[[ 0.0184  0.9816]\n",
      " [ 0.002   0.998 ]\n",
      " [ 0.8797  0.1203]\n",
      " [ 0.9809  0.0191]\n",
      " [ 0.0001  0.9999]\n",
      " [ 0.0099  0.9901]\n",
      " [ 0.9102  0.0898]\n",
      " [ 0.3978  0.6022]\n",
      " [ 0.6796  0.3204]\n",
      " [ 0.0134  0.9866]]\n"
     ]
    }
   ],
   "source": [
    "filenames = test_batches.filenames\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "print(filenames[:10])\n",
    "print(preds[:10])\n",
    "#our_labels = np.round(preds[:, 0])\n",
    "#our_labels[:10]\n",
    "#our_preds = preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknown/cat.10923.jpg',\n",
       " 'unknown/dog.571.jpg',\n",
       " 'unknown/cat.12414.jpg',\n",
       " 'unknown/cat.6013.jpg',\n",
       " 'unknown/cat.2881.jpg',\n",
       " 'unknown/dog.3678.jpg',\n",
       " 'unknown/cat.2445.jpg',\n",
       " 'unknown/cat.11129.jpg',\n",
       " 'unknown/cat.359.jpg',\n",
       " 'unknown/cat.9922.jpg']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(preds[:10])\n",
    "filenames = test_batches.filenames\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2ad761c6edfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexpected_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "expected_labels = get_test_labels(test_batches.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
