{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/deeplearning\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/deeplearning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 1: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN 5110)\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu1')\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "#path=\"../data/2cat/sample\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink\n",
    "from keras.preprocessing import image, sequence\n",
    "import os, sys, cv2\n",
    "from shutil import copyfile, move\n",
    "from random import shuffle\n",
    "\n",
    "####\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n"
     ]
    }
   ],
   "source": [
    "data_dir=\"/home/asaeed9/work/data/2cat\"\n",
    "path=\"/home/asaeed9/work/data/2cat/sample/\"\n",
    "results_path = \"/home/asaeed9/work/data/2cat/sample/results\"\n",
    "test_path = path + '/test/' #We use all the test data\n",
    "global last_file_timestamp\n",
    "%cd ../data/2cat/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_prev_data_sample():\n",
    "    %mv $path/train/cats/* $data_dir/train/\n",
    "    %mv $path/train/dogs/* $data_dir/train/\n",
    "    %mv $path/valid/cats/* $data_dir/train/\n",
    "    %mv $path/valid/dogs/* $data_dir/train/\n",
    "\n",
    "#clean previous data\n",
    "def adjust_prev_data():\n",
    "    %mv $data_dir/valid/* $data_dir/train/    \n",
    "    adjust_prev_data_sample()\n",
    "\n",
    "#move training images\n",
    "def move_from_test(new_trainset, path, train, validation):\n",
    "    print(new_trainset[:10])\n",
    "    \n",
    "def move_to_test(images):\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(images): os.rename(shuf[i], '../sample/test/' + shuf[i]) \n",
    "    %mv ../sample/test/cat*.jpg ../sample/test/cats/\n",
    "    %mv ../sample/test/dog*.jpg ../sample/test/dogs/      \n",
    "\n",
    "    \n",
    "def handle_null(train, validation):\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(train): copyfile(shuf[i], '../sample/train/' + shuf[i]) \n",
    "    %mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "    %mv ../sample/train/dog*.jpg ../sample/train/dogs/\n",
    "    \n",
    "    %cd ../valid\n",
    "\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(validation): copyfile(shuf[i], '../sample/valid/' + shuf[i]) \n",
    "    %mv ../sample/valid/cat*.jpg ../sample/valid/cats/\n",
    "    %mv ../sample/valid/dog*.jpg ../sample/valid/dogs/\n",
    "    %cd $data_dir/train\n",
    "    \n",
    "#copy training images\n",
    "def copy_samples(train, validation):\n",
    "    #print(\"Copying new samples for training...\")\n",
    "    #clean previous data\n",
    "    adjust_prev_data()\n",
    "    \n",
    "    #build validation set\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(validation): os.rename(shuf[i], '../valid/' + shuf[i]) \n",
    "    \n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(train): copyfile(shuf[i], '../sample/train/' + shuf[i]) \n",
    "    %mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "    %mv ../sample/train/dog*.jpg ../sample/train/dogs/\n",
    "    \n",
    "    %cd ../valid\n",
    "\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(validation): copyfile(shuf[i], '../sample/valid/' + shuf[i]) \n",
    "    %mv ../sample/valid/cat*.jpg ../sample/valid/cats/\n",
    "    %mv ../sample/valid/dog*.jpg ../sample/valid/dogs/\n",
    "    %cd $data_dir/train\n",
    "\n",
    "def onehot(x): return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())\n",
    "\n",
    "def pred_batch(imgs, classes):\n",
    "    preds = model.predict(imgs)\n",
    "    idxs = np.argmax(preds, axis=1)\n",
    "\n",
    "    print('Shape: {}'.format(preds.shape))\n",
    "    print('First 5 classes: {}'.format(classes[:5]))\n",
    "    print('First 5 probabilities: {}\\n'.format(preds[:5]))\n",
    "    print('Predictions prob/class: ')\n",
    "    \n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        print ('  {:.4f}/{}'.format(preds[i, idx], classes[idx]))\n",
    "\n",
    "\n",
    "def generate_size_graph(fig_no, training_size, accuracy, loss, start_size, end_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(training_size,accuracy)\n",
    "    plt.plot(training_size,loss)\n",
    "    plt.xlabel('Training Size')\n",
    "    plt.ylabel('Accuracy/Loss')\n",
    "    plt.title('Training Size vs Accuracy/Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['Accuracy','Loss'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(path + '/batch_graphs/' +  str(start_size) + '_' + str(end_size) + '.jpg') \n",
    "        \n",
    "def generate_graph(fig_no, epochs, train, val, label, train_title, val_title, train_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(epochs,train)\n",
    "    plt.plot(epochs,val)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel(label)\n",
    "    plt.title(train_title + ' vs ' + val_title + '( Samples:' + str(train_size) + ')')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(results_path + '/batch_graphs/' +  label + '_' + str(train_size) + '.jpg') \n",
    "    \n",
    "def get_train_model(tr_batches, val_batches, epoch):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3, 256,256)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "#             Convolution2D(64,3,3, activation='relu'),\n",
    "#             BatchNormalization(axis=1),\n",
    "            #MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Flatten(),\n",
    "            Dense(1024, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=epoch - 2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model \n",
    "\n",
    "def train_model(model, tr_batches, val_batches, epoch):\n",
    "    if not model:\n",
    "        model = Sequential([\n",
    "                BatchNormalization(axis=1, input_shape=(3, 256,256)),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Dropout(0.2),\n",
    "    #             Convolution2D(64,3,3, activation='relu'),\n",
    "    #             BatchNormalization(axis=1),\n",
    "                #MaxPooling2D((3,3)),\n",
    "                Convolution2D(64,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Dropout(0.2),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Dropout(0.2),\n",
    "                Flatten(),\n",
    "                Dense(1024, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dropout(0.2),\n",
    "                Dense(2, activation='softmax')\n",
    "            ])\n",
    "        model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "       \n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=epoch - 2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "        \n",
    "    return model \n",
    "    \n",
    "    \n",
    "def get_test_model():\n",
    "    model = Sequential([\n",
    "                BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "    #             Convolution2D(64,3,3, activation='relu'),\n",
    "    #             BatchNormalization(axis=1),\n",
    "                #MaxPooling2D((3,3)),\n",
    "                Convolution2D(64,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Flatten(),\n",
    "                Dense(1024, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dense(2, activation='softmax')\n",
    "            ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    \n",
    "    return model\n",
    "\n",
    "def fit(samples_copied, old_model, path, results_path, nepoch, batch_size, train_size, valid_size):\n",
    "    gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "\n",
    "    #for train in training_range:\n",
    "    model = None\n",
    "    if not samples_copied:\n",
    "        copy_samples(train_size, valid_size)\n",
    "\n",
    "    tr_batches = gen_t.flow_from_directory(path + 'train', batch_size=batch_size)\n",
    "    val_batches = gen_t.flow_from_directory(path + 'valid', class_mode='categorical', shuffle=True, batch_size=batch_size * 2)\n",
    "    \n",
    "    if old_model:\n",
    "        model = train_model(old_model, tr_batches, val_batches, nepoch)\n",
    "    else:\n",
    "        model = train_model(None, tr_batches, val_batches, nepoch)\n",
    "        \n",
    "    #model.save_weights(results_path+ '/' + 'ft_' + str(train_size) + '.e' + str(nepoch))\n",
    "    last_file_timestamp = '{:%Y%m%d%H%M%S}'.format(datetime.datetime.now())\n",
    "    #print('File Time Stamp:{}'.format(last_file_timestamp))\n",
    "    model.save_weights(results_path+'/ft_{}'.format(last_file_timestamp))\n",
    "    #model.load_weights(results_path+'/ft_{}'.format(last_file_timestamp))\n",
    "                          \n",
    "    return model, last_file_timestamp\n",
    "\n",
    "def predict(path, model):\n",
    "    gen_test = image.ImageDataGenerator()\n",
    "    test_batches = gen_test.flow_from_directory(path+'test', class_mode=None, target_size=(256,256), shuffle=False, batch_size=1)\n",
    "    test_data = np.concatenate([test_batches.next() for i in range(test_batches.nb_sample)])\n",
    "    test_labels = onehot(test_batches.classes)\n",
    "    score = model.evaluate(test_data, test_labels)\n",
    "    \n",
    "    probs = model.predict(test_data)\n",
    "    \n",
    "    #loss_score.append(score[0])\n",
    "    #accuracy_score.append(score[1])\n",
    "    \n",
    "    print(\"\\nLoss:{}, Accuracy:{}\".format(score[0], score[1]))\n",
    "    #print(\"\\nProbabilities:{}\".format(probs))\n",
    "    return probs, test_batches, score[0], score[1]\n",
    "\n",
    "def move_samples(retrain_set,dest_path, n, limit):\n",
    "    cats_copied = 0\n",
    "    dogs_copied = 0\n",
    "    retrain_list = list(retrain_set)\n",
    "    shuffle(retrain_list)\n",
    "    for fil in range(n):\n",
    "        fil = retrain_list.pop()\n",
    "        fil_cpy = fil[fil.find('/')+1:]\n",
    "\n",
    "        if 'cat' in fil_cpy and cats_copied <= limit:\n",
    "            os.rename(os.path.join(path + \"test/cats/\"+ fil_cpy), os.path.join(path + dest_path + \"/cats/\"+ fil_cpy))\n",
    "            cats_copied+=1\n",
    "        elif 'dog' in fil_cpy and dogs_copied <= limit:\n",
    "            os.rename(os.path.join(path + \"test/dogs/\"+ fil_cpy), os.path.join(path + dest_path + \"/dogs/\" + fil_cpy))\n",
    "            dogs_copied+=1\n",
    "            \n",
    "    #print(\"Limit:\", limit)        \n",
    "    #print(\"moved cats:\", cats_copied)\n",
    "    #print(\"moved dogs:\", dogs_copied)\n",
    "    #print(\"Retrain Length: \", len(retrain_list))\n",
    "    return retrain_list, cats_copied, dogs_copied\n",
    "\n",
    "\n",
    "def move_to_train(retrain_set, limit):\n",
    "    cats = 0\n",
    "    dogs = 0\n",
    "    valid_limit = int(math.floor(.2*(limit*2)))\n",
    "    train_limit = int(math.floor(.8*(limit*2)))\n",
    "    \n",
    "    #print(retrain_set[:10])\n",
    "    print(\"validation set: \", valid_limit)\n",
    "    retrain_list, cats_copied, dogs_copied = move_samples(retrain_set, \"valid\", valid_limit, limit)\n",
    "    valid_size = cats_copied + dogs_copied\n",
    "    print(\"Train set: \", train_limit)\n",
    "    retrain_list, cats_copied, dogs_copied = move_samples(retrain_list, \"train\", train_limit, limit)\n",
    "    train_size = cats_copied + dogs_copied\n",
    "    \n",
    "    return train_size, valid_size, train_size + valid_size\n",
    "\n",
    "def refil_test(nimages):\n",
    "    os.chdir(\"/home/asaeed9/work/data/2cat/train\")\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(nimages): os.rename(shuf[i], '../sample/test/' + shuf[i])\n",
    "    #os.chdir(\"../sample/test/\")\n",
    "    #move(\"cat*.jpg\")\n",
    "    %mv ../sample/test/cat*.jpg ../sample/test/cats/\n",
    "    %mv ../sample/test/dog*.jpg ../sample/test/dogs/     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n",
      "Train Size:100\n",
      "Valid Size:20\n",
      "/home/asaeed9/work/data/2cat/valid\n",
      "/home/asaeed9/work/data/2cat/train\n",
      "Found 100 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 1s - loss: 0.8525 - acc: 0.5500 - val_loss: 1.4459 - val_acc: 0.7000\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 1s - loss: 0.9482 - acc: 0.5100 - val_loss: 0.9429 - val_acc: 0.6000\n",
      "Epoch 1/28\n",
      "100/100 [==============================] - 1s - loss: 0.9513 - acc: 0.6300 - val_loss: 0.7411 - val_acc: 0.6000\n",
      "Epoch 2/28\n",
      "100/100 [==============================] - 1s - loss: 0.9643 - acc: 0.5500 - val_loss: 0.7594 - val_acc: 0.5000\n",
      "Epoch 3/28\n",
      "100/100 [==============================] - 1s - loss: 1.0104 - acc: 0.5600 - val_loss: 0.7829 - val_acc: 0.4500\n",
      "Epoch 4/28\n",
      "100/100 [==============================] - 1s - loss: 0.8822 - acc: 0.6400 - val_loss: 0.8724 - val_acc: 0.3000\n",
      "Epoch 5/28\n",
      "100/100 [==============================] - 1s - loss: 1.0309 - acc: 0.5200 - val_loss: 0.8721 - val_acc: 0.4000\n",
      "Epoch 6/28\n",
      "100/100 [==============================] - 1s - loss: 0.7060 - acc: 0.6500 - val_loss: 0.7166 - val_acc: 0.5500\n",
      "Epoch 7/28\n",
      "100/100 [==============================] - 1s - loss: 0.8570 - acc: 0.6000 - val_loss: 0.6953 - val_acc: 0.7000\n",
      "Epoch 8/28\n",
      "100/100 [==============================] - 1s - loss: 0.7139 - acc: 0.7100 - val_loss: 0.6387 - val_acc: 0.6500\n",
      "Epoch 9/28\n",
      "100/100 [==============================] - 1s - loss: 0.6097 - acc: 0.7700 - val_loss: 0.6865 - val_acc: 0.6000\n",
      "Epoch 10/28\n",
      "100/100 [==============================] - 1s - loss: 0.6929 - acc: 0.6500 - val_loss: 0.7029 - val_acc: 0.6000\n",
      "Epoch 11/28\n",
      "100/100 [==============================] - 0s - loss: 0.6001 - acc: 0.7600 - val_loss: 0.6678 - val_acc: 0.6000\n",
      "Epoch 12/28\n",
      "100/100 [==============================] - 1s - loss: 0.6707 - acc: 0.6500 - val_loss: 0.6751 - val_acc: 0.6500\n",
      "Epoch 13/28\n",
      "100/100 [==============================] - 1s - loss: 0.6291 - acc: 0.6900 - val_loss: 0.6300 - val_acc: 0.6500\n",
      "Epoch 14/28\n",
      "100/100 [==============================] - 1s - loss: 0.8422 - acc: 0.6100 - val_loss: 0.6256 - val_acc: 0.6500\n",
      "Epoch 15/28\n",
      "100/100 [==============================] - 1s - loss: 0.5698 - acc: 0.7300 - val_loss: 0.7038 - val_acc: 0.6500\n",
      "Epoch 16/28\n",
      "100/100 [==============================] - 1s - loss: 0.5883 - acc: 0.7700 - val_loss: 0.6448 - val_acc: 0.6500\n",
      "Epoch 17/28\n",
      "100/100 [==============================] - 1s - loss: 0.5896 - acc: 0.7800 - val_loss: 0.6412 - val_acc: 0.6500\n",
      "Epoch 18/28\n",
      "100/100 [==============================] - 1s - loss: 0.5718 - acc: 0.7900 - val_loss: 0.7016 - val_acc: 0.6500\n",
      "Epoch 19/28\n",
      "100/100 [==============================] - 0s - loss: 0.6091 - acc: 0.7400 - val_loss: 0.6524 - val_acc: 0.6500\n",
      "Epoch 20/28\n",
      "100/100 [==============================] - 1s - loss: 0.4317 - acc: 0.7700 - val_loss: 0.6650 - val_acc: 0.6500\n",
      "Epoch 21/28\n",
      "100/100 [==============================] - 1s - loss: 0.6254 - acc: 0.7200 - val_loss: 0.6372 - val_acc: 0.7000\n",
      "Epoch 22/28\n",
      "100/100 [==============================] - 1s - loss: 0.5685 - acc: 0.7800 - val_loss: 0.6632 - val_acc: 0.6500\n",
      "Epoch 23/28\n",
      "100/100 [==============================] - 1s - loss: 0.3714 - acc: 0.8100 - val_loss: 0.6371 - val_acc: 0.6500\n",
      "Epoch 24/28\n",
      "100/100 [==============================] - 1s - loss: 0.6983 - acc: 0.6100 - val_loss: 0.6429 - val_acc: 0.7000\n",
      "Epoch 25/28\n",
      "100/100 [==============================] - 1s - loss: 0.6226 - acc: 0.7100 - val_loss: 0.6302 - val_acc: 0.6500\n",
      "Epoch 26/28\n",
      "100/100 [==============================] - 1s - loss: 0.4986 - acc: 0.7300 - val_loss: 0.6729 - val_acc: 0.6500\n",
      "Epoch 27/28\n",
      "100/100 [==============================] - 1s - loss: 0.6449 - acc: 0.7300 - val_loss: 0.6658 - val_acc: 0.6500\n",
      "Epoch 28/28\n",
      "100/100 [==============================] - 1s - loss: 0.5262 - acc: 0.7600 - val_loss: 0.6662 - val_acc: 0.7000\n",
      "Found 2998 images belonging to 2 classes.\n",
      "2976/2998 [============================>.] - ETA: 0s\n",
      "Loss:0.642902997989, Accuracy:0.680787191461\n",
      "validation set:  90\n",
      "Train set:  360\n",
      "Training Set Size:[100]\n",
      "Accuracy:[0.68078719146097399]\n",
      "Loss:[0.64290299798903106]\n"
     ]
    }
   ],
   "source": [
    "%cd $data_dir/train\n",
    "\n",
    "nepoch = 30\n",
    "batch_size = 64\n",
    "train_size = 100\n",
    "retrain_sample_size = 100\n",
    "running_train_size = 100\n",
    "training_set_size = []\n",
    "valid_size = int(math.floor(.2 * train_size))\n",
    "#print('sample size: {}'.format(train_size + valid_size))\n",
    "tr_model = None\n",
    "loss = 0.0\n",
    "loss_array = []\n",
    "accuracy = 0.0\n",
    "accuracy_array = []\n",
    "\n",
    "#copy test data\n",
    "#move_to_test(3000)\n",
    "\n",
    "i=0\n",
    "#for i in range(100):\n",
    "print(\"Train Size:{}\".format(train_size))\n",
    "print(\"Valid Size:{}\".format(valid_size))\n",
    "\n",
    "if train_size == 0 or valid_size == 0: #handle null case\n",
    "    handle_null(50,10)\n",
    "    train_size += 50\n",
    "    valid_size += 10\n",
    "\n",
    "tr_model,file_timestamp = fit(i, tr_model, path, results_path, nepoch, batch_size, train_size, valid_size)\n",
    "\n",
    "model = None\n",
    "model = get_test_model() \n",
    "#model.load_weights(results_path+'/ft_' + str(train_size) + '.e' + str(nepoch))\n",
    "#print('{0}/ft_{1}'.format(last_file_timestamp))\n",
    "#print('Last File Timestamp- before loading:{}'.format(file_timestamp))\n",
    "model.load_weights(results_path+'/ft_{}'.format(file_timestamp))\n",
    "\n",
    "probs, test_batches,loss, accuracy = predict(path, model)\n",
    "training_set_size.append(running_train_size)\n",
    "loss_array.append(loss)\n",
    "accuracy_array.append(accuracy)\n",
    "\n",
    "\n",
    "#get the top 100, most confused images\n",
    "retrain_idx = np.argsort(probs[:,0] - probs[:, 1])[:retrain_sample_size]\n",
    "\n",
    "retrain_set = [test_batches.filenames[i] for i in retrain_idx]\n",
    "\n",
    "os.chdir(path + 'test')\n",
    "ndog = sum('dog' in name for name in retrain_set)\n",
    "ncat =  sum('cat' in name for name in retrain_set)\n",
    "limit = min(ncat, ndog)\n",
    "\n",
    "#move existing training data to the store\n",
    "adjust_prev_data_sample()\n",
    "train_size, valid_size, copied_images = move_to_train(retrain_set, limit)\n",
    "running_train_size += train_size\n",
    "refil_test(copied_images)\n",
    "\n",
    "print('Training Set Size:{}'.format(training_set_size))\n",
    "print('Accuracy:{}'.format(accuracy_array))\n",
    "print('Loss:{}'.format(loss_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_probs = probs[:3, :]\n",
    "\n",
    "np.argsort(sample_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8215,  0.1785],\n",
       "       [ 0.7075,  0.2925],\n",
       "       [ 0.6634,  0.3366]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6431,  0.4149,  0.3267], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_probs[:3,0] - sample_probs[:3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(sample_probs[:3,0] - sample_probs[:3, 1])[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(probs[:2,0] - probs[:2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.where(sorted(abs(probs[:2,0] - probs[:2,1])))[0]\n",
    "\n",
    "#np.where(np.logical_and(probs >=0.4, probs<=0.7))[0]\n",
    "#np.where()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(abs(probs[:,0] - probs[:, 1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Training Set Size:[100, 255, 507, 544, 586, 669, 727, 786, 829, 1097, 1166, 1288, 1322, 1610, 1795, 1979, 2124, 2384, 2555, 2707, 2903, 3015, 3078, 3151, 3306, 3424, 3480, 3544, 3614, 3762, 3984, 4203, 4355, 4502, 4638, 4758, 4830, 4918, 4974, 5002, 5014, 5049, 5083, 5108, 5121, 5163, 5196, 5271, 5297, 5338, 5377, 5442, 5478, 5585, 5647, 5744, 5804, 5842, 5885, 5926, 5964, 5990, 5996, 6050, 6098, 6114, 6137, 6156, 6292, 6360, 6493, 6603, 6641, 6672, 6705, 6740, 6856, 6885, 6969, 7022, 7057, 7103, 7119, 7137, 7157, 7167, 7170, 7192, 7259, 7279, 7326, 7368, 7409, 7489, 7508, 7519, 7535, 7565, 7577, 7593]\n",
    "Accuracy:[0.51834556370913942, 0.53235490327878665, 0.54069379586390931, 0.55103402269172863, 0.56370913944616563, 0.56170780524323194, 0.57171447635730799, 0.57738492332195102, 0.59472981993956431, 0.607738492358041, 0.61674449629112427, 0.62408272182448377, 0.65310206809506721, 0.6711140761103449, 0.67645096735130394, 0.69246164113382569, 0.68478985995630803, 0.70180120085023734, 0.71247498336197779, 0.72214809877225128, 0.70713809210113721, 0.71180787194443196, 0.72014676454943605, 0.72481654442255306, 0.71581054040000314, 0.72581721151407919, 0.72314876587371812, 0.72848565714449942, 0.73048699128778871, 0.73982655113342999, 0.74583055378199414, 0.76951300877185569, 0.77451634432889371, 0.77718478995931395, 0.76484322889873868, 0.77818545695143271, 0.78118745826577407, 0.77318212137451325, 0.76751167440987011, 0.77151434285550058, 0.77384923278211837, 0.77985323556985275, 0.77451634418972337, 0.78452301542308822, 0.77585056700493349, 0.77384923278211837, 0.7795196797467614, 0.78685790532982458, 0.77985323545056395, 0.76984656442595456, 0.78519012681081191, 0.78952635096024482, 0.79319546360266535, 0.80453635753195152, 0.80553702464335919, 0.7871914609541012, 0.79719813204829582, 0.80020013338251861, 0.79786524345590082, 0.79619746493688814, 0.78819212804562733, 0.79452968641787547, 0.79853235486350593, 0.79919946639039974, 0.80086724479012361, 0.79886591056730849, 0.79986657767871605, 0.71881254179387033, 0.79686457634449326, 0.77484989991340736, 0.8115410273316862, 0.81387591735771136, 0.81087391602348857, 0.81187458303548876, 0.81120747174717256, 0.80820547029366085, 0.81654436288872423, 0.8042028018480305, 0.81621080728432904, 0.82154769854516962, 0.8232154769448935, 0.82188125412968338, 0.81420947306151392, 0.81420947306151392, 0.79786524357518962, 0.79919946627111094, 0.81854569721094683, 0.81387591735771136, 0.81454302866590911, 0.79953302199479503, 0.81320880596998768, 0.81521014007351411, 0.82088058715744605, 0.81154102731180477, 0.81120747172729102, 0.81420947296210655, 0.81854569711153946, 0.81621080728432904, 0.81721147427644791, 0.81187458301560733]\n",
    "Loss:[0.94627340202573307, 1.069129374521903, 1.6582751717068021, 1.9458960867508639, 1.7672291246949234, 1.8073495392544099, 2.2642813132276847, 2.1801735833585463, 1.4026525458786947, 1.9107522724806427, 2.0852411977643568, 1.885862276673794, 1.4222142591804088, 1.6198320426966366, 1.4607558314246762, 1.637531633791405, 1.6699402961753225, 1.4755695811345468, 1.4915868397193244, 1.3634724204066277, 1.7743482206655472, 1.8913224160949575, 1.6106715754042313, 1.3743048965970701, 1.565028794591947, 1.9099577603696425, 1.9002086268719274, 1.8303540087018593, 1.4808997903727468, 1.0050827415884933, 1.0144933128929521, 1.0415886528218405, 1.0145420589750811, 1.1418929995895626, 1.1928224458226846, 1.4710475567024974, 1.341952260054295, 1.8395282249944938, 2.3651828057511031, 2.3124792167279753, 2.305378243448915, 2.0921286372747461, 2.2739992053878604, 2.3005914534378444, 2.2752316740566392, 2.1230344122071925, 1.8697313540941323, 1.9767550084891519, 2.3808871660582858, 2.0304581639465638, 1.6816643132226141, 1.7091403857570606, 1.255017541860882, 1.4477932849790829, 1.3391912613831973, 1.695395214437166, 1.6405188316495478, 1.883696767807832, 1.8168773716272137, 2.1832812890025841, 2.5262706354183559, 2.199554436640943, 1.8084424575585736, 1.9852745032712713, 1.9270797232017987, 1.9817351747420384, 2.3064219975595739, 1.7742115364939948, 1.6118588206358875, 1.3782198212002021, 1.2986096903791102, 1.6194246127093093, 1.8720587353657601, 1.7112238509897353, 1.764265245251641, 1.3266987558938885, 1.6663410443420572, 1.6504295845829779, 1.7126746936698132, 1.9551829461497892, 1.7929846915162309, 2.0409724012221035, 2.1942079734076447, 2.3111469137771712, 2.2224564307727781, 2.5554216508963821, 2.0883331067482378, 1.6952288752798241, 2.1873511853298768, 2.0337138844416631, 1.9773875592814496, 1.9745328070035451, 1.6287168510223404, 2.3116104998768714, 2.2300192884155075, 2.162166691486481, 2.0174554670189169, 2.2769914772579942, 2.1841097289998905, 2.3013370820185077]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_size_graph(1, training_set_size, accuracy_array, loss_array, min(training_set_size), max(training_set_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
