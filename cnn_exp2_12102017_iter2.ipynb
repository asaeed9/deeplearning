{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/deeplearning\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/deeplearning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 1: GeForce GTX 980 Ti (CNMeM is disabled, cuDNN 5110)\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu1')\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "#path=\"../data/2cat/sample\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink\n",
    "from keras.preprocessing import image, sequence\n",
    "import os, sys, cv2\n",
    "from shutil import copyfile, move\n",
    "from random import shuffle\n",
    "\n",
    "####\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n"
     ]
    }
   ],
   "source": [
    "data_dir=\"/home/asaeed9/work/data/2cat\"\n",
    "path=\"/home/asaeed9/work/data/2cat/sample/\"\n",
    "results_path = \"/home/asaeed9/work/data/2cat/sample/results\"\n",
    "test_path = path + '/test/' #We use all the test data\n",
    "global last_file_timestamp\n",
    "%cd ../data/2cat/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_prev_data_sample():\n",
    "    %mv $path/train/cats/* $data_dir/train/\n",
    "    %mv $path/train/dogs/* $data_dir/train/\n",
    "    %mv $path/valid/cats/* $data_dir/train/\n",
    "    %mv $path/valid/dogs/* $data_dir/train/\n",
    "    \n",
    "#clean previous data\n",
    "def adjust_prev_data():\n",
    "    %mv $data_dir/valid/* $data_dir/train/    \n",
    "    adjust_prev_data_sample()\n",
    "\n",
    "def move_data(images, kind, clean):\n",
    "    \n",
    "    if clean:\n",
    "        %mv $path/$kind/cats/* $data_dir/train/\n",
    "        %mv $path/$kind/dogs/* $data_dir/train/\n",
    "        \n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(images): os.rename(shuf[i], '../sample/'+ kind + '/' + shuf[i]) \n",
    "    %mv ../sample/$kind/cat*.jpg ../sample/$kind/cats/\n",
    "    %mv ../sample/$kind/dog*.jpg ../sample/$kind/dogs/      \n",
    "\n",
    "# def move_to_unlabel(images):\n",
    "#     g = glob('*.jpg')\n",
    "#     shuf = np.random.permutation(g)\n",
    "#     for i in range(images): os.rename(shuf[i], '../sample/unlabel/' + shuf[i]) \n",
    "#     %mv ../sample/unlabel/cat*.jpg ../sample/unlabel/cats/\n",
    "#     %mv ../sample/unlabel/dog*.jpg ../sample/unlabel/dogs/      \n",
    "    \n",
    "    \n",
    "def handle_null(train, validation):\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(train): copyfile(shuf[i], '../sample/train/' + shuf[i]) \n",
    "    %mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "    %mv ../sample/train/dog*.jpg ../sample/train/dogs/\n",
    "    \n",
    "    %cd ../valid\n",
    "\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(validation): copyfile(shuf[i], '../sample/valid/' + shuf[i]) \n",
    "    %mv ../sample/valid/cat*.jpg ../sample/valid/cats/\n",
    "    %mv ../sample/valid/dog*.jpg ../sample/valid/dogs/\n",
    "    %cd $data_dir/train\n",
    "    \n",
    "#copy training images\n",
    "def copy_samples(train, validation):\n",
    "    #print(\"Copying new samples for training...\")\n",
    "    #clean previous data\n",
    "    adjust_prev_data()\n",
    "    \n",
    "    #build validation set\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(validation): os.rename(shuf[i], '../valid/' + shuf[i]) \n",
    "    \n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(train): copyfile(shuf[i], '../sample/train/' + shuf[i]) \n",
    "    %mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "    %mv ../sample/train/dog*.jpg ../sample/train/dogs/\n",
    "    \n",
    "    %cd ../valid\n",
    "\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(validation): copyfile(shuf[i], '../sample/valid/' + shuf[i]) \n",
    "    %mv ../sample/valid/cat*.jpg ../sample/valid/cats/\n",
    "    %mv ../sample/valid/dog*.jpg ../sample/valid/dogs/\n",
    "    %cd $data_dir/train\n",
    "\n",
    "def onehot(x): return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())\n",
    "\n",
    "def pred_batch(imgs, classes):\n",
    "    preds = model.predict(imgs)\n",
    "    idxs = np.argmax(preds, axis=1)\n",
    "\n",
    "    print('Shape: {}'.format(preds.shape))\n",
    "    print('First 5 classes: {}'.format(classes[:5]))\n",
    "    print('First 5 probabilities: {}\\n'.format(preds[:5]))\n",
    "    print('Predictions prob/class: ')\n",
    "    \n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        print ('  {:.4f}/{}'.format(preds[i, idx], classes[idx]))\n",
    "\n",
    "\n",
    "def generate_size_graph(fig_no, training_size, accuracy, loss, start_size, end_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(training_size,accuracy)\n",
    "    plt.plot(training_size,loss)\n",
    "    plt.xlabel('Training Size')\n",
    "    plt.ylabel('Accuracy/Loss')\n",
    "    plt.title('Training Size vs Accuracy/Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['Accuracy','Loss'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(path + '/batch_graphs/' +  str(start_size) + '_' + str(end_size) + '.jpg') \n",
    "        \n",
    "def generate_graph(fig_no, epochs, train, val, label, train_title, val_title, train_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(epochs,train)\n",
    "    plt.plot(epochs,val)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel(label)\n",
    "    plt.title(train_title + ' vs ' + val_title + '( Samples:' + str(train_size) + ')')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(results_path + '/batch_graphs/' +  label + '_' + str(train_size) + '.jpg') \n",
    "    \n",
    "def get_train_model(tr_batches, val_batches, epoch):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3, 256,256)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "#             Convolution2D(64,3,3, activation='relu'),\n",
    "#             BatchNormalization(axis=1),\n",
    "            #MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Flatten(),\n",
    "            Dense(1024, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=epoch - 2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model \n",
    "\n",
    "def train_model(model, tr_batches, val_batches, epoch):\n",
    "    if not model:\n",
    "        model = Sequential([\n",
    "                BatchNormalization(axis=1, input_shape=(3, 256,256)),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Dropout(0.2),\n",
    "    #             Convolution2D(64,3,3, activation='relu'),\n",
    "    #             BatchNormalization(axis=1),\n",
    "                #MaxPooling2D((3,3)),\n",
    "                Convolution2D(64,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Dropout(0.2),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Dropout(0.2),\n",
    "                Flatten(),\n",
    "                Dense(1024, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dropout(0.2),\n",
    "                Dense(2, activation='softmax')\n",
    "            ])\n",
    "        model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "       \n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    \n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=1, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    \n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(tr_batches, tr_batches.nb_sample, nb_epoch=epoch - 3, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "        \n",
    "    return model \n",
    "    \n",
    "    \n",
    "def get_test_model():\n",
    "    model = Sequential([\n",
    "                BatchNormalization(axis=1, input_shape=(3,256,256)),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "    #             Convolution2D(64,3,3, activation='relu'),\n",
    "    #             BatchNormalization(axis=1),\n",
    "                #MaxPooling2D((3,3)),\n",
    "                Convolution2D(64,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Convolution2D(32,3,3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Flatten(),\n",
    "                Dense(1024, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dense(2, activation='softmax')\n",
    "            ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    \n",
    "    return model\n",
    "\n",
    "def fit(samples_copied, old_model, path, results_path, nepoch, batch_size, train_size, valid_size):\n",
    "    gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "\n",
    "    #for train in training_range:\n",
    "    model = None\n",
    "    if not samples_copied:\n",
    "        copy_samples(train_size, valid_size)\n",
    "\n",
    "    tr_batches = gen_t.flow_from_directory(path + 'train', batch_size=batch_size)\n",
    "    val_batches = gen_t.flow_from_directory(path + 'valid', class_mode='categorical', shuffle=True, batch_size=batch_size * 2)\n",
    "    \n",
    "    if old_model:\n",
    "        model = train_model(old_model, tr_batches, val_batches, nepoch)\n",
    "    else:\n",
    "        model = train_model(None, tr_batches, val_batches, nepoch)\n",
    "        \n",
    "    #model.save_weights(results_path+ '/' + 'ft_' + str(train_size) + '.e' + str(nepoch))\n",
    "    last_file_timestamp = '{:%Y%m%d%H%M%S}'.format(datetime.datetime.now())\n",
    "    #print('File Time Stamp:{}'.format(last_file_timestamp))\n",
    "    model.save_weights(results_path+'/ft_{}'.format(last_file_timestamp))\n",
    "    #model.load_weights(results_path+'/ft_{}'.format(last_file_timestamp))\n",
    "                          \n",
    "    return model, last_file_timestamp\n",
    "\n",
    "def predict(path, model, predict_type):\n",
    "    gen_test = image.ImageDataGenerator()\n",
    "    test_batches = gen_test.flow_from_directory(path+predict_type, class_mode=None, target_size=(256,256), shuffle=False, batch_size=1)\n",
    "    test_data = np.concatenate([test_batches.next() for i in range(test_batches.nb_sample)])\n",
    "    test_labels = onehot(test_batches.classes)\n",
    "    score = model.evaluate(test_data, test_labels)\n",
    "    \n",
    "    probs = model.predict(test_data)\n",
    "    \n",
    "    #loss_score.append(score[0])\n",
    "    #accuracy_score.append(score[1])\n",
    "    \n",
    "    #print(\"\\nLoss:{}, Accuracy:{}\".format(score[0], score[1]))\n",
    "    #print(\"\\nProbabilities:{}\".format(probs))\n",
    "    return probs, test_batches, score[0], score[1]\n",
    "\n",
    "def move_samples(retrain_set,dest_path, n, limit):\n",
    "    cats_copied = 0\n",
    "    dogs_copied = 0\n",
    "    retrain_list = list(retrain_set)\n",
    "    shuffle(retrain_list)\n",
    "    for fil in range(n):\n",
    "        fil = retrain_list.pop()\n",
    "        fil_cpy = fil[fil.find('/')+1:]\n",
    "\n",
    "        if 'cat' in fil_cpy and cats_copied <= limit:\n",
    "            os.rename(os.path.join(path + \"unlabel/cats/\"+ fil_cpy), os.path.join(path + dest_path + \"/cats/\"+ fil_cpy))\n",
    "            cats_copied+=1\n",
    "        elif 'dog' in fil_cpy and dogs_copied <= limit:\n",
    "            os.rename(os.path.join(path + \"unlabel/dogs/\"+ fil_cpy), os.path.join(path + dest_path + \"/dogs/\" + fil_cpy))\n",
    "            dogs_copied+=1\n",
    "            \n",
    "    #print(\"Limit:\", limit)        \n",
    "    #print(\"moved cats:\", cats_copied)\n",
    "    #print(\"moved dogs:\", dogs_copied)\n",
    "    #print(\"Retrain Length: \", len(retrain_list))\n",
    "    return retrain_list, cats_copied, dogs_copied\n",
    "\n",
    "\n",
    "def move_to_train(retrain_set, limit):\n",
    "    cats = 0\n",
    "    dogs = 0\n",
    "    valid_limit = int(math.floor(.2*(limit*2)))\n",
    "    train_limit = int(math.floor(.8*(limit*2)))\n",
    "    \n",
    "    #print(retrain_set[:10])\n",
    "    print(\"validation set: \", valid_limit)\n",
    "    retrain_list, cats_copied, dogs_copied = move_samples(retrain_set, \"valid\", valid_limit, limit)\n",
    "    valid_size = cats_copied + dogs_copied\n",
    "    print(\"Train set: \", train_limit)\n",
    "    retrain_list, cats_copied, dogs_copied = move_samples(retrain_list, \"train\", train_limit, limit)\n",
    "    train_size = cats_copied + dogs_copied\n",
    "    \n",
    "    return train_size, valid_size, train_size + valid_size\n",
    "\n",
    "def refil_unlabel(nimages):\n",
    "    os.chdir(\"/home/asaeed9/work/data/2cat/train\")\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(nimages): os.rename(shuf[i], '../sample/unlabel/' + shuf[i])\n",
    "    #os.chdir(\"../sample/test/\")\n",
    "    #move(\"cat*.jpg\")\n",
    "    %mv ../sample/unlabel/cat*.jpg ../sample/unlabel/cats/\n",
    "    %mv ../sample/unlabel/dog*.jpg ../sample/unlabel/dogs/     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move_data(2000, 'test', True)\n",
    "move_data(2000, 'unlabel', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/data/2cat/train\n",
      "Train Size:100\n",
      "Valid Size:20\n",
      "/home/asaeed9/work/data/2cat/valid\n",
      "/home/asaeed9/work/data/2cat/train\n",
      "Found 100 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 2s - loss: 1.0509 - acc: 0.5200 - val_loss: 0.9611 - val_acc: 0.4000\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 1s - loss: 1.1760 - acc: 0.4700 - val_loss: 0.9166 - val_acc: 0.4000\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s - loss: 0.9314 - acc: 0.5700 - val_loss: 0.8550 - val_acc: 0.3000\n",
      "Epoch 1/37\n",
      "100/100 [==============================] - 2s - loss: 0.7350 - acc: 0.6600 - val_loss: 0.7711 - val_acc: 0.3500\n",
      "Epoch 2/37\n",
      "100/100 [==============================] - 1s - loss: 0.9549 - acc: 0.5800 - val_loss: 0.8371 - val_acc: 0.3000\n",
      "Epoch 3/37\n",
      "100/100 [==============================] - 1s - loss: 0.9871 - acc: 0.5800 - val_loss: 0.8167 - val_acc: 0.3000\n",
      "Epoch 4/37\n",
      "100/100 [==============================] - 1s - loss: 0.6619 - acc: 0.6700 - val_loss: 0.7044 - val_acc: 0.6000\n",
      "Epoch 5/37\n",
      "100/100 [==============================] - 1s - loss: 0.8801 - acc: 0.6900 - val_loss: 0.8024 - val_acc: 0.3500\n",
      "Epoch 6/37\n",
      "100/100 [==============================] - 1s - loss: 0.5098 - acc: 0.7700 - val_loss: 0.8186 - val_acc: 0.3500\n",
      "Epoch 7/37\n",
      "100/100 [==============================] - 1s - loss: 0.8467 - acc: 0.6400 - val_loss: 0.7673 - val_acc: 0.3500\n",
      "Epoch 8/37\n",
      "100/100 [==============================] - 1s - loss: 0.6526 - acc: 0.6900 - val_loss: 0.8413 - val_acc: 0.4000\n",
      "Epoch 9/37\n",
      "100/100 [==============================] - 1s - loss: 0.5417 - acc: 0.7500 - val_loss: 0.8742 - val_acc: 0.4000\n",
      "Epoch 10/37\n",
      "100/100 [==============================] - 1s - loss: 0.4795 - acc: 0.8300 - val_loss: 0.8149 - val_acc: 0.4500\n",
      "Epoch 11/37\n",
      "100/100 [==============================] - 1s - loss: 0.4874 - acc: 0.7400 - val_loss: 0.9361 - val_acc: 0.4000\n",
      "Epoch 12/37\n",
      "100/100 [==============================] - 1s - loss: 0.5899 - acc: 0.7400 - val_loss: 0.8704 - val_acc: 0.4000\n",
      "Epoch 13/37\n",
      "100/100 [==============================] - 1s - loss: 0.6045 - acc: 0.7400 - val_loss: 0.9693 - val_acc: 0.4000\n",
      "Epoch 14/37\n",
      "100/100 [==============================] - 1s - loss: 0.5896 - acc: 0.7200 - val_loss: 1.0016 - val_acc: 0.4000\n",
      "Epoch 15/37\n",
      "100/100 [==============================] - 1s - loss: 0.5364 - acc: 0.8000 - val_loss: 0.9454 - val_acc: 0.4000\n",
      "Epoch 16/37\n",
      "100/100 [==============================] - 1s - loss: 0.5140 - acc: 0.7500 - val_loss: 0.9993 - val_acc: 0.4000\n",
      "Epoch 17/37\n",
      "100/100 [==============================] - 1s - loss: 0.5519 - acc: 0.7700 - val_loss: 1.0643 - val_acc: 0.4000\n",
      "Epoch 18/37\n",
      "100/100 [==============================] - 1s - loss: 0.5904 - acc: 0.7000 - val_loss: 1.0219 - val_acc: 0.4000\n",
      "Epoch 19/37\n",
      "100/100 [==============================] - 1s - loss: 0.2984 - acc: 0.8800 - val_loss: 1.0390 - val_acc: 0.4000\n",
      "Epoch 20/37\n",
      "100/100 [==============================] - 1s - loss: 0.5655 - acc: 0.7500 - val_loss: 1.0755 - val_acc: 0.4000\n",
      "Epoch 21/37\n",
      "100/100 [==============================] - 1s - loss: 0.3496 - acc: 0.8300 - val_loss: 1.0658 - val_acc: 0.4000\n",
      "Epoch 22/37\n",
      "100/100 [==============================] - 1s - loss: 0.3884 - acc: 0.8100 - val_loss: 1.1460 - val_acc: 0.4000\n",
      "Epoch 23/37\n",
      "100/100 [==============================] - 1s - loss: 0.5220 - acc: 0.8100 - val_loss: 1.1732 - val_acc: 0.4000\n",
      "Epoch 24/37\n",
      "100/100 [==============================] - 1s - loss: 0.6081 - acc: 0.7700 - val_loss: 1.1456 - val_acc: 0.4000\n",
      "Epoch 25/37\n",
      "100/100 [==============================] - 1s - loss: 0.5113 - acc: 0.8400 - val_loss: 1.2896 - val_acc: 0.4000\n",
      "Epoch 26/37\n",
      "100/100 [==============================] - 1s - loss: 0.3779 - acc: 0.8400 - val_loss: 1.2401 - val_acc: 0.4000\n",
      "Epoch 27/37\n",
      "100/100 [==============================] - 1s - loss: 0.4167 - acc: 0.8000 - val_loss: 1.4184 - val_acc: 0.4000\n",
      "Epoch 28/37\n",
      "100/100 [==============================] - 1s - loss: 0.3451 - acc: 0.8500 - val_loss: 1.4562 - val_acc: 0.4000\n",
      "Epoch 29/37\n",
      "100/100 [==============================] - 1s - loss: 0.5330 - acc: 0.7700 - val_loss: 1.6091 - val_acc: 0.4000\n",
      "Epoch 30/37\n",
      "100/100 [==============================] - 1s - loss: 0.3034 - acc: 0.8700 - val_loss: 1.6406 - val_acc: 0.4000\n",
      "Epoch 31/37\n",
      "100/100 [==============================] - 1s - loss: 0.4051 - acc: 0.8100 - val_loss: 1.7796 - val_acc: 0.4000\n",
      "Epoch 32/37\n",
      "100/100 [==============================] - 1s - loss: 0.3489 - acc: 0.8700 - val_loss: 1.8442 - val_acc: 0.4000\n",
      "Epoch 33/37\n",
      "100/100 [==============================] - 1s - loss: 0.4456 - acc: 0.8200 - val_loss: 1.9460 - val_acc: 0.4000\n",
      "Epoch 34/37\n",
      "100/100 [==============================] - 1s - loss: 0.2963 - acc: 0.8400 - val_loss: 2.0266 - val_acc: 0.4000\n",
      "Epoch 35/37\n",
      "100/100 [==============================] - 1s - loss: 0.2229 - acc: 0.9000 - val_loss: 2.1000 - val_acc: 0.4000\n",
      "Epoch 36/37\n",
      "100/100 [==============================] - 1s - loss: 0.4116 - acc: 0.8300 - val_loss: 2.1822 - val_acc: 0.4000\n",
      "Epoch 37/37\n",
      "100/100 [==============================] - 1s - loss: 0.3259 - acc: 0.7800 - val_loss: 2.1696 - val_acc: 0.4000\n",
      "\n",
      "Verification on Unlabel set.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "2000/2000 [==============================] - 2s     \n",
      "\n",
      "Unlabel Accuracy:0.55\n",
      "Unlabel Loss:1.63868062496\n",
      "validation set:  335\n",
      "Train set:  1340\n",
      "\n",
      "Verification on Test set.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "2000/2000 [==============================] - 2s     \n",
      "\n",
      "Training Set Size:[100]\n",
      "Accuracy:[0.4945]\n",
      "Loss:[1.8295054642856121]\n",
      "Train Size:1340\n",
      "Valid Size:335\n",
      "Found 1440 images belonging to 2 classes.\n",
      "Found 355 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      " 832/1440 [================>.............] - ETA: 7s - loss: 1.0407 - acc: 0.5950"
     ]
    }
   ],
   "source": [
    "%cd $data_dir/train\n",
    "\n",
    "nepoch = 40\n",
    "batch_size = 64\n",
    "train_size = 100\n",
    "running_train_size = 100\n",
    "retrain_size = 1800\n",
    "training_set_size = []\n",
    "valid_size = int(math.floor(.2 * train_size))\n",
    "#print('sample size: {}'.format(train_size + valid_size))\n",
    "tr_model = None\n",
    "loss = 0.0\n",
    "loss_array = []\n",
    "accuracy = 0.0\n",
    "accuracy_array = []\n",
    "\n",
    "#copy test data\n",
    "#move_data(2000, 'test', True)\n",
    "#move_data(2000, 'unlabel', True)\n",
    "\n",
    "i=0\n",
    "for i in range(200):\n",
    "    print(\"Train Size:{}\".format(train_size))\n",
    "    print(\"Valid Size:{}\".format(valid_size))\n",
    "\n",
    "    if train_size == 0 or valid_size == 0: #handle null case\n",
    "        handle_null(50,10)\n",
    "        train_size += 50\n",
    "        valid_size += 10\n",
    "\n",
    "    tr_model,file_timestamp = fit(i, tr_model, path, results_path, nepoch, batch_size, train_size, valid_size)\n",
    "\n",
    "    model = None\n",
    "    model = get_test_model() \n",
    "    #model.load_weights(results_path+'/ft_' + str(train_size) + '.e' + str(nepoch))\n",
    "    #print('{0}/ft_{1}'.format(last_file_timestamp))\n",
    "    #print('Last File Timestamp- before loading:{}'.format(file_timestamp))\n",
    "    model.load_weights(results_path+'/ft_{}'.format(file_timestamp))\n",
    "\n",
    "    print(\"\\nVerification on Unlabel set.\")\n",
    "    probs, test_batches,loss, accuracy = predict(path, model, \"unlabel\")\n",
    "    print('\\nUnlabel Accuracy:{}'.format(accuracy))\n",
    "    print('Unlabel Loss:{}'.format(loss))    \n",
    "#     training_set_size.append(running_train_size)\n",
    "#     loss_array.append(loss)\n",
    "#     accuracy_array.append(accuracy)\n",
    "\n",
    "    #get the top 100, most confused images\n",
    "    retrain_idx = np.argsort(probs[:,0] - probs[:, 1])[:retrain_size]\n",
    "    #print(len(retrain_idx))\n",
    "\n",
    "    retrain_set = [test_batches.filenames[i] for i in retrain_idx]\n",
    "\n",
    "    #print('Retrain Set Length:{}'.format(len(retrain_set)))\n",
    "\n",
    "    os.chdir(path + 'unlabel')\n",
    "    ndog = sum('dog' in name for name in retrain_set)\n",
    "    ncat =  sum('cat' in name for name in retrain_set)\n",
    "    limit = min(ncat, ndog)\n",
    "\n",
    "    #print('Dogs:{}, Cats:{}'.format(ndog, ncat))\n",
    "\n",
    "    #move existing training data to the store\n",
    "    #adjust_prev_data_sample()\n",
    "    train_size, valid_size, copied_images = move_to_train(retrain_set, limit)\n",
    "    refil_unlabel(copied_images)\n",
    "    \n",
    "\n",
    "    print(\"\\nVerification on Test set.\")\n",
    "    model_test = None\n",
    "    model_test = get_test_model() \n",
    "    #model.load_weights(results_path+'/ft_' + str(train_size) + '.e' + str(nepoch))\n",
    "    #print('{0}/ft_{1}'.format(last_file_timestamp))\n",
    "    #print('Last File Timestamp- before loading:{}'.format(file_timestamp))\n",
    "    model_test.load_weights(results_path+'/ft_{}'.format(file_timestamp))\n",
    "\n",
    "    probs, test_batches,loss, accuracy = predict(path, model_test, \"test\")\n",
    "    training_set_size.append(running_train_size)\n",
    "    loss_array.append(loss)\n",
    "    accuracy_array.append(accuracy)\n",
    "\n",
    "    running_train_size += train_size\n",
    "\n",
    "    print('\\nTraining Set Size:{}'.format(training_set_size))\n",
    "    print('Accuracy:{}'.format(accuracy_array))\n",
    "    print('Loss:{}'.format(loss_array))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_probs = probs[:3, :]\n",
    "\n",
    "np.argsort(sample_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_probs[:3,0] - sample_probs[:3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argsort(sample_probs[:3,0] - sample_probs[:3, 1])[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(probs[:2,0] - probs[:2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "np.where(sorted(abs(probs[:2,0] - probs[:2,1])))[0]\n",
    "\n",
    "#np.where(np.logical_and(probs >=0.4, probs<=0.7))[0]\n",
    "#np.where()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.where(abs(probs[:,0] - probs[:, 1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_size = [100, 1504, 2928, 4302, 5722, 7126, 8558, 9966, 11394, 12827, 14204, 15618, 17045, 18427, 19863, 21275, 22699, 24115, 25548, 26916]\n",
    "accuracy_array = [0.50649999999999995, 0.62, 0.67300000000000004, 0.73750000000000004, 0.77200000000000002, 0.79449999999999998, 0.8145, 0.82750000000000001, 0.85099999999999998, 0.85550000000000004, 0.85650000000000004, 0.86550000000000005, 0.876, 0.89049999999999996, 0.88549999999999995, 0.89349999999999996, 0.90249999999999997, 0.89800000000000002, 0.91100000000000003, 0.92000000000000004]\n",
    "loss_array = [1.5634963861703872, 1.3101546764373779, 1.3389599814414979, 0.9770810330510139, 0.90527572575211523, 0.77679392026364802, 0.70273019789159297, 0.66951325211301449, 0.53929746384918686, 0.47854575932025911, 0.48957985889911654, 0.40410763838887215, 0.37995399814844133, 0.34014862793684003, 0.38376239252462985, 0.33013378190994264, 0.33610362323373555, 0.31462397079169752, 0.29526432225108146, 0.28285194587707518]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFNCAYAAACUvLFdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4aRnZmbFcNIzM7NiOOmZmVkx/geoWcTwcFaVFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb58004d950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb51b99c790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_size_graph(1, training_set_size, accuracy_array, loss_array, min(training_set_size), max(training_set_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
