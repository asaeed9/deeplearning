{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Data Path Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* some configurations for convolutional neuralnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asaeed9/work/deeplearning\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/deeplearning/\n",
    "batch_size=16\n",
    "\n",
    "path=\"/home/asaeed9/work/data/2cat/sample/\"\n",
    "results_path = \"/home/asaeed9/work/data/2cat/sample/results\"\n",
    "\n",
    "train_path = path + \"/train\"\n",
    "valid_path = path + \"/valid\"\n",
    "test_path = path + \"/test\"\n",
    "\n",
    "img_rows=128\n",
    "img_cols=128\n",
    "num_channel=1\n",
    "num_epoch=20\n",
    "num_classes = 2\n",
    "\n",
    "names = ['cats','dogs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following function takes the input as path to the data, and returns grey-scaled images and labels for those images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_greyed_images(data_path):\n",
    "    data_dir_list = os.listdir(data_path)\n",
    "    img_data_list=[]\n",
    "    labels=[]\n",
    "\n",
    "    for dataset in data_dir_list:\n",
    "        img_list=os.listdir(data_path+'/'+ dataset)\n",
    "        print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "        for img in img_list:\n",
    "\n",
    "            if 'cat' in img:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "\n",
    "            input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "            input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "            input_img_resize=cv2.resize(input_img,(128,128))\n",
    "            img_data_list.append(input_img_resize)\n",
    "\n",
    "    img_data = np.array(img_data_list)\n",
    "    img_data = img_data.astype('float32')\n",
    "    img_data /= 255\n",
    "    print (img_data.shape) \n",
    "    return img_data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-dogs\n",
      "\n",
      "Loaded the images of dataset-cats\n",
      "\n",
      "(1500, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "train_img_data, train_labels = get_greyed_images(train_path)\n",
    "#expand a dimension to add 1 to the shape of train_img_data\n",
    "train_img_data= np.expand_dims(train_img_data, axis=1) \n",
    "train_nsamples = train_img_data.shape[0]\n",
    "train_input_shape=train_img_data[0].shape\n",
    "\n",
    "train_Y = np_utils.to_categorical(train_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-dogs\n",
      "\n",
      "Loaded the images of dataset-cats\n",
      "\n",
      "(500, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "valid_img_data, valid_labels = get_greyed_images(valid_path)\n",
    "#expand a dimension to add 1 to the shape of train_img_data\n",
    "valid_img_data= np.expand_dims(valid_img_data, axis=1) \n",
    "valid_nsamples = valid_img_data.shape[0]\n",
    "valid_input_shape=valid_img_data[0].shape\n",
    "\n",
    "valid_Y = np_utils.to_categorical(valid_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-dogs\n",
      "\n",
      "Loaded the images of dataset-cats\n",
      "\n",
      "(3000, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "test_img_data, test_labels = get_greyed_images(test_path)\n",
    "test_img_data = np.expand_dims(test_img_data, axis=1)\n",
    "test_nsamples = test_img_data.shape[0]\n",
    "test_input_shape=test_img_data[0].shape\n",
    "\n",
    "test_Y = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model on Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following function defines a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, 3,3,border_mode='same',input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Convolution2D(64, 3, 3))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following code calls the above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_4 (Convolution2D)  (None, 32, 128, 128)  320         convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 32, 128, 128)  0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 32, 126, 126)  9248        activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 32, 126, 126)  0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 32, 63, 63)    0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 32, 63, 63)    0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 64, 61, 61)    18496       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 64, 61, 61)    0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 64, 30, 30)    0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 64, 30, 30)    0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 57600)         0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 64)            3686464     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 64)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 64)            0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2)             130         dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 2)             0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,714,658\n",
      "Trainable params: 3,714,658\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.7827 - acc: 0.5020 - val_loss: 0.6968 - val_acc: 0.4900\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.6922 - acc: 0.5247 - val_loss: 0.6843 - val_acc: 0.5440\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.6871 - acc: 0.5747 - val_loss: 0.6720 - val_acc: 0.6060\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.6532 - acc: 0.6127 - val_loss: 0.6709 - val_acc: 0.5880\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.6090 - acc: 0.6627 - val_loss: 0.6216 - val_acc: 0.6580\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.5705 - acc: 0.7113 - val_loss: 0.6288 - val_acc: 0.6520\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.5374 - acc: 0.7447 - val_loss: 0.6222 - val_acc: 0.6700\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.5078 - acc: 0.7520 - val_loss: 0.6199 - val_acc: 0.6740\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.4627 - acc: 0.7813 - val_loss: 0.6226 - val_acc: 0.6420\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.4353 - acc: 0.7920 - val_loss: 0.6295 - val_acc: 0.6600\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.4127 - acc: 0.8060 - val_loss: 0.6703 - val_acc: 0.6880\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.3820 - acc: 0.8233 - val_loss: 0.6639 - val_acc: 0.6780\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.3664 - acc: 0.8353 - val_loss: 0.7637 - val_acc: 0.6300\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.3354 - acc: 0.8533 - val_loss: 0.6665 - val_acc: 0.6560\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.3219 - acc: 0.8540 - val_loss: 0.7770 - val_acc: 0.6820\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.3252 - acc: 0.8573 - val_loss: 0.6982 - val_acc: 0.6980\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.3003 - acc: 0.8787 - val_loss: 0.7587 - val_acc: 0.6820\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.2744 - acc: 0.8873 - val_loss: 0.7831 - val_acc: 0.6720\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 3s - loss: 0.2971 - acc: 0.8827 - val_loss: 0.8329 - val_acc: 0.7000\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 4s - loss: 0.2589 - acc: 0.8860 - val_loss: 0.9464 - val_acc: 0.6840\n"
     ]
    }
   ],
   "source": [
    "model = get_cnn_model(train_input_shape)\n",
    "model.summary()\n",
    "hist = model.fit(train_img_data, train_Y, batch_size=16, nb_epoch=num_epoch, verbose=1, validation_data=(valid_img_data, valid_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Make Predictions on the Learned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00203098  0.99796897]\n",
      " [ 0.26495466  0.73504537]\n",
      " [ 0.00867537  0.99132466]\n",
      " ..., \n",
      " [ 0.30260459  0.69739538]\n",
      " [ 0.10978741  0.89021254]\n",
      " [ 0.9154247   0.08457533]]\n",
      "[1 1 1 ..., 1 1 0]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "class 0(cats)       0.70      0.68      0.69      1497\n",
      "class 1(Dogs)       0.69      0.71      0.70      1503\n",
      "\n",
      "  avg / total       0.70      0.70      0.70      3000\n",
      "\n",
      "[[1022  475]\n",
      " [ 433 1070]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(test_img_data)\n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "#print(y_pred)\n",
    "target_names = ['class 0(cats)', 'class 1(Dogs)']\n",
    "\n",
    "print(classification_report(np.argmax(test_Y,axis=1), y_pred,target_names=target_names))\n",
    "\n",
    "print(confusion_matrix(np.argmax(test_Y,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
