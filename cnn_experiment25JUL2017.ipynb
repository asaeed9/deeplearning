{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')\n",
    "import os, cv2, sys\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import *\n",
    "from keras.optimizers import SGD,RMSprop,Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Data Path Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* some configurations for convolutional neuralnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/work/deeplearning/\n",
    "batch_size=16\n",
    "\n",
    "path=\"/home/asaeed9/work/data/2cat/sample/\"\n",
    "results_path = \"/home/asaeed9/work/data/2cat/sample/results\"\n",
    "\n",
    "train_path = path + \"/train\"\n",
    "valid_path = path + \"/valid\"\n",
    "test_path = path + \"/test\"\n",
    "\n",
    "img_rows=128\n",
    "img_cols=128\n",
    "num_channel=1\n",
    "num_epoch=60\n",
    "num_classes = 2\n",
    "\n",
    "batch = []\n",
    "batch_accuracy = []\n",
    "batch_loss = []\n",
    "\n",
    "names = ['cats','dogs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following functions copies(removes existing data first) different sizes of train/validation set for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean previous data\n",
    "def clean_up():\n",
    "    %rm $path/train/cats/*\n",
    "    %rm $path/train/dogs/*\n",
    "    %rm $path/valid/cats/*\n",
    "    %rm $path/valid/dogs/*\n",
    "\n",
    "#copy training images\n",
    "def copy_samples(train, validation):\n",
    "    %cd ../data/2cat/train\n",
    "    #clean previous data\n",
    "    clean_up()\n",
    "    \n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(train): copyfile(shuf[i], '../sample/train/' + shuf[i]) \n",
    "    %mv ../sample/train/cat*.jpg ../sample/train/cats/\n",
    "    %mv ../sample/train/dog*.jpg ../sample/train/dogs/\n",
    "    \n",
    "    %cd ../valid\n",
    "\n",
    "    g = glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(validation): copyfile(shuf[i], '../sample/valid/' + shuf[i]) \n",
    "    %mv ../sample/valid/cat*.jpg ../sample/valid/cats/\n",
    "    %mv ../sample/valid/dog*.jpg ../sample/valid/dogs/\n",
    "    %cd ~/work/deeplearning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following function takes the input as path to the data, and returns grey-scaled images and labels for those images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_greyed_images(data_path):\n",
    "    data_dir_list = os.listdir(data_path)\n",
    "    img_data_list=[]\n",
    "    labels=[]\n",
    "\n",
    "    for dataset in data_dir_list:\n",
    "        img_list=os.listdir(data_path+'/'+ dataset)\n",
    "        print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "        for img in img_list:\n",
    "\n",
    "            if 'cat' in img:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "\n",
    "            input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "            input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "            input_img_resize=cv2.resize(input_img,(128,128))\n",
    "            img_data_list.append(input_img_resize)\n",
    "\n",
    "    img_data = np.array(img_data_list)\n",
    "    img_data = img_data.astype('float32')\n",
    "    img_data /= 255\n",
    "    print (img_data.shape) \n",
    "    return img_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_images(data_path):\n",
    "    data_dir_list = os.listdir(data_path)\n",
    "    img_data_list=[]\n",
    "    labels=[]\n",
    "\n",
    "    for dataset in data_dir_list:\n",
    "        img_list=os.listdir(data_path+'/'+ dataset)\n",
    "        print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "        for img in img_list:\n",
    "\n",
    "            if 'cat' in img:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "            img_data_list.append(input_img_resize)\n",
    "\n",
    "    img_data = np.array(img_data_list)\n",
    "    img_data = img_data.astype('float32')\n",
    "    return img_data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Training, Validation, and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_data(train_size, valid_size):\n",
    "    copy_samples(train_size, valid_size)\n",
    "    \n",
    "#     #Training Data\n",
    "#     train_img_data, train_labels = get_greyed_images(train_path)\n",
    "#     #expand a dimension to add 1 to the shape of train_img_data\n",
    "#     train_img_data= np.expand_dims(train_img_data, axis=1) \n",
    "#     train_nsamples = train_img_data.shape[0]\n",
    "#     train_input_shape=train_img_data[0].shape\n",
    "\n",
    "#     train_Y = np_utils.to_categorical(train_labels, num_classes)\n",
    "\n",
    "#     #Validation Data\n",
    "\n",
    "#     valid_img_data, valid_labels = get_greyed_images(valid_path)\n",
    "#     #expand a dimension to add 1 to the shape of train_img_data\n",
    "#     valid_img_data= np.expand_dims(valid_img_data, axis=1) \n",
    "#     valid_nsamples = valid_img_data.shape[0]\n",
    "#     valid_input_shape=valid_img_data[0].shape\n",
    "\n",
    "#     valid_Y = np_utils.to_categorical(valid_labels, num_classes)\n",
    "\n",
    "\n",
    "    #Test Data\n",
    "    test_img_data, test_labels = get_greyed_images(test_path)\n",
    "    test_img_data = np.expand_dims(test_img_data, axis=1)\n",
    "    test_nsamples = test_img_data.shape[0]\n",
    "    test_input_shape=test_img_data[0].shape\n",
    "\n",
    "    test_Y = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model on Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following function defines a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    #model.add(BatchNormalization(axis=1, input_shape=input_shape))\n",
    "    model.add(Convolution2D(32, 3,3,border_mode='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, activity_regularizer=regularizers.l2(0.01)))\n",
    "    #model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Convolution2D(100, 3, 3, activity_regularizer=regularizers.l2(0.01)))\n",
    "    #model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Convolution2D(64, 3, 3))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, activity_regularizer=regularizers.l2(0.01)))\n",
    "    #model.add(BatchNormalization(axis=1))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Convolution2D(64, 3, 3))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.3))\n",
    "    \n",
    "#     model.add(Convolution2D(32, 3, 3))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.5))    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200,  activity_regularizer=regularizers.l2(0.01)))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.001, momentum=0.2, nesterov=True)\n",
    "    adm = Adam()\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_II(train_batches, val_batches, input_shape):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=input_shape),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "#             Convolution2D(64,3,3, activation='relu'),\n",
    "#             BatchNormalization(axis=1),\n",
    "            #MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Dropout(0.2),\n",
    "            Flatten(),\n",
    "            Dense(1024, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "#                      nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=50, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following code sets up the data and build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epoch = 60\n",
    "train_size = 18000\n",
    "valid_size = int(math.floor(.2 * train_size))\n",
    "setup_data(train_size, valid_size)\n",
    "model = get_cnn_model(train_input_shape)\n",
    "#model.summary()\n",
    "hist = model.fit(train_img_data, train_Y, batch_size=16, nb_epoch=num_epoch, verbose=1, validation_data=(valid_img_data, valid_Y))\n",
    "model.save_weights(results_path + '/ft_'+ str(len(train_img_data))+ '.e' + str(num_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(results_path + '/ft_' + str(len(train_img_data))+ '.e' + str(num_epoch))\n",
    "score = model.evaluate(test_img_data, test_Y, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# batch.append(len(train_img_data))\n",
    "# batch_accuracy.append(score[1])\n",
    "# batch_loss.append(score[0])\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "\n",
    "\n",
    "generate_graph(1, range(num_epoch), train_loss, val_loss, 'Loss', 'Train Loss', 'Validation Loss', train_size)\n",
    "generate_graph(2, range(num_epoch), train_acc, val_acc, 'Accuracy', 'Train Accuracy', 'Validation Accuracy', train_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following functions generate graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_graph(fig_no, epochs, train, val, label, train_title, val_title, train_size):\n",
    "    plt.figure(fig_no,figsize=(7,5))\n",
    "    plt.plot(epochs,train)\n",
    "    plt.plot(epochs,val)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel(label)\n",
    "    plt.title(train_title + ' vs ' + val_title + '( Samples:' + str(train_size) + ')')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'])\n",
    "    plt.style.use(['classic'])\n",
    "    plt.show()\n",
    "    plt.savefig(results_path + '/batch_graphs/' +  label + '_' + str(train_size) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(test_img_data)\n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "#y_pred = model.predict_classes(X_test)\n",
    "#print(y_pred)\n",
    "target_names = ['class 0(cats)', 'class 1(Dogs)']\n",
    "\n",
    "print(classification_report(np.argmax(test_Y,axis=1), y_pred,target_names=target_names))\n",
    "\n",
    "print(confusion_matrix(np.argmax(test_Y,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_pred[:20]\n",
    "#np.argmax(test_Y, axis=1)[:20]\n",
    "\n",
    "correct = np.where(y_pred == np.argmax(test_Y, axis=1))\n",
    "accuracy = float(len(correct[0]))/float(len(test_Y))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = cv2.imread(test_path + '/cats/cat.6296.jpg')\n",
    "test_image=cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "test_image=cv2.resize(test_image,(128,128))\n",
    "test_image = np.array(test_image)\n",
    "test_image = test_image.astype('float32')\n",
    "test_image /= 255\n",
    "\n",
    "\n",
    "test_image= np.expand_dims(test_image, axis=0)\n",
    "test_image= np.expand_dims(test_image, axis=0)\n",
    "\n",
    "print((model.predict(test_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig=plt.figure(figsize=(16,16))\n",
    "\n",
    "type(test_image)\n",
    "\n",
    "#plt.imshow(test_image[:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
